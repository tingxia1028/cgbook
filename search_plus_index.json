{"./":{"url":"./","title":"Introduction","keywords":"","body":"Introduction 这里将以gitbook的形式整理关于computer graphics的一些资料 包括但不限于 读书笔记/总结 网上资源搜集整理 手敲demo的记录 开源引擎源码的学习 商业引擎的使用和开发技能 paper阅读和实现 工作中的思考总结 课程笔记 Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-06-14 16:41:26 "},"space_trans/resource.html":{"url":"space_trans/resource.html","title":"Space Transformation","keywords":"","body":"Resources Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-03-07 13:37:40 "},"camera/resource.html":{"url":"camera/resource.html","title":"Camera","keywords":"","body":"Resources GAMES 101 相机与透镜 解释了很多之前学摄影课时其实没有真正理解的东西。 Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-03-27 23:02:44 "},"camera/photography/photography.html":{"url":"camera/photography/photography.html","title":"科学解释摄影中的一些概念","keywords":"","body":"科学解释摄影中的一些概念 为啥小于24毫米的被叫做超广角或是鱼眼镜头 --- FOV 为啥画幅越大的相机成像范围越大 手机那么小是如何保证fov的呢 我们常说的曝光是什么 ISO究竟是个啥，为什么调高ISO噪点也变多了 快门到底是咋工作的 如何调节曝光 手机是如何实现变焦的，明明没有什么镜头伸缩的空间啊 景深到底是个啥原理 为什么光圈设置的数值越小反而说光圈越大 跑个题，ray tracing是如何模拟物体相机的 看完了闫兄的那节课，感觉一个爱好摄影的理工科生得到了解脱，就是终于tm的我知道是为啥了。 为啥小于24毫米的被叫做超广角或是鱼眼镜头 --- FOV 为啥画幅越大的相机成像范围越大 手机那么小是如何保证fov的呢 缩短焦距 我们常说的曝光是什么 所以如何控制曝光： 光圈，快门， ISO（熟悉的摄影三要素啊！！！） ISO究竟是个啥，为什么调高ISO噪点也变多了 change the amplification (analog and/or digital) between sensor values and digital image values multiply signal before analog-to-digital conversion 相当于把irradiance线性的乘以一个值，ISO越大乘的倍数越大。 线性乘的时候，噪声也会被线性放大，所以感觉噪点变多了。 快门到底是咋工作的 抬起取景器，放下快门，升起快门 于是可以有motion blur的效果。 rolling shutter的side effect.(果冻效应，讲真感觉不太能get到为什么翻译成果冻效应，并不形象啊) 如何调节曝光 我想要大光圈，又不能过曝，就得减小快门时间。那减少多少的快门时间呢? eg. 光圈 F 2.0 到 光圈 F1.4 1/2.0 -> 1/1.4 ，直径增大差不多是 根号2倍，光圈面积增大2倍，于是快门要缩小2倍，也就是快门时间 * 0.5, 就从1/250 变成 1/500. 手机是如何实现变焦的，明明没有什么镜头伸缩的空间啊 通过一个透镜组来实现不同的焦距。 景深到底是个啥原理 焦距物距像距的关系 理想的薄透镜，根据三角形相似可以得到 Circle Of Confusion(COC) size 模糊效果是跟光圈大小有关系的 Depth of Field 成像清晰的一段范围 COC大小和像素大小差不多的时候是锐利的 sensor离透镜越近，DOF越大，行话景深越小 焦距越小，DOF越大，行话景深越小 光圈直径越小(光圈数值越大, 行话光圈越小)，DOF越大，行话景深越小 COC越大，DOF越大，行话景深越小 为什么光圈设置的数值越小反而说光圈越大 Informal understanding: F number = the inverse-diameter of a round aperture (1/光圈直径) Formal definition: F number = the focal length divided by the diameter of the aperture （f/光圈直径） 所以光圈越大，DOF越小，模糊的范围越大，行话说景深越大。 跑个题，ray tracing是如何模拟物体相机的 Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-03-28 00:39:03 "},"ray_tracing/resource.html":{"url":"ray_tracing/resource.html","title":"Ray Tracing","keywords":"","body":"Resources Entry Level 闫令琪的games101 lecture 13 - 16 很好的一门CG基础课程，看视频比较容易看的进去 Peter Shirley 的入门三部曲，很适合初学者，并且一定要跟着手敲一遍，会加深理解 Ray Tracing in One Weekend Ray Tracing: The Next Week Ray Tracing: The Rest of Your Life courses Utah CS6620 Fall 2019 Ray Tracing for Graphics 虽然没有课件，但是课后作业设计的不错 UCSD CSE168 computer graphics 2 : rendering 介绍了rt的一些基础知识, 感觉看课件pdf就可以没必要看视频 UCSD CSE 272: Advanced Image Synthesis 更偏离线渲染，可以看做CSE168的进阶课程，看看课件，配合课程提供的mini离线渲染器lajolla Renderer做一做作业还是不错的 Advanced Level NVDIA出品的Ray Tracing Gems DirectX Raytracing introduction and a demo Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-02-08 11:56:08 "},"ray_tracing/sampling/resource.html":{"url":"ray_tracing/sampling/resource.html","title":"Sampling","keywords":"","body":"Resources RTR Chapter13, Monte Carlo Integration Unity 18, Sampling the GGX Distribution of Visible Normals Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-07-19 11:37:26 "},"ray_tracing/sampling/montecarlo/montecarlo.html":{"url":"ray_tracing/sampling/montecarlo/montecarlo.html","title":"Monte Carlo Integration","keywords":"","body":"Monte Carlo Integration why Monte Carlo Integration Background and Probability Review canonical uniform random variable variance The Monte Carlo Estimator Sampling Random Variable The Inversion Method The Rejection Method Metropolis Sampling main ideas example estimate integrals disadvantages Transforming between Distributions 2D Sampling with Multidimensional Transformations 如何提高积分器的效率 efficiency of an estimator Russian Roulette and Splitting Russian Roulette splitting Careful Sample Placement Stratified Sampling Quasi Monte Carlo 引入bias Importance Sampling 这篇笔记整体的逻辑是： 我想估计一个积分值，有哪些方法, 为什么Monte Carlo Integration可以脱颖而出 Monte Carlo Integration是个啥原理 --- Monte Carlo estimator 给定了一个Monte Carlo estimator，我应该如何得到samples 如何评估一个Monte Carlo estimator的好坏 怎样让自己的Monte Carlo estimator更好 why Monte Carlo Integration 相比于rapezoidal integration or Gaussian quadrature, Monte Carlo integration makes it possible to estimate the reflected radiance simply by choosing a set of directions over the sphere, computing the incident radiance along them, multiplying by the BSDF’s value for those directions, and applying a weighting term. The main disadvantage of Monte Carlo is that if n samples are used to estimate the integral, the algorithm converges to the correct result at a rate of O(n^(1/2)). Most of the current research in Monte Carlo for computer graphics is about reducing this error as much as possible while minimizing the number of additional samples that must be taken. Background and Probability Review canonical uniform random variable 均匀随机采样重要的原因是： it is easy to generate a variable with this distribution in software it is possible to generate samples from arbitrary distributions by first starting with canonical uniform random variables and applying an appropriate transformation variance Variance is a fundamental concept for quantifying the error in a value estimated by a Monte Carlo algorithm. It provides a precise way to quantify this error and measure how improvements to Monte Carlo algorithms reduce the error in the final result. The Monte Carlo Estimator estimator --- approximates the value of an arbitrary integral unbias independent of the sample nums N and the dimensionality of the integral rate of convergence O(n^(1/2)) Sampling Random Variable The Inversion Method 等于是计算出cdf, 然后以一个均匀随机采样去获得[0,1]的随机数 y，然后反算出cdf(x) = y的x值是多少作为采样值。 The Rejection Method Metropolis Sampling a technique for generating a set of samples from a non-negative function that is distributed proportionally to f ’s value (Metropolis et al. 1953). main ideas start-up X_0 make mutation from X_i-1 to X_i --- transition function T 和前一个sample有关 和前一个sample无关，随机 weather new X_i is accepted --- acceptance probability a final target --- equilibrium pseudocode example 上面的理论听起来还是太抽象，用实际的例子来理解是最好不过的。 为了拟合以下概率密度函数，采用两种mutation的方式 uniform random ---- 不会一直陷入一个small region出不来 random offset --- 收敛速度更快，方差小 comparison estimate integrals 其实这里没太懂。。。这里的近似有点像之前games202里说的chebyshelve不等式近似。 disadvantages successive samples in the sequence are statistically correlated, and it may needs more samples so can well distributed across the domain. Transforming between Distributions 我们通常是用一种简单好采样的distribution(eg. uniform random)去转换到目标的distribution上，那这个转换函数怎么得到？ 一维 转换函数必须是一种 one-to-one transformation： 推广到多维 联想到render equation最常用的半球积分 2D Sampling with Multidimensional Transformations 基本的思想是 先根据p(x)得到x的一个sample，再根据p(y|x)分布得到y的一个sample. 以均匀球面采样为例 求得cdf，求逆，得到均匀采样如何转换到均匀球面采样 Malley’s method --- 正好带到之前看SSR的GGX visible normal中的采样方法 就是把单位球的cos(theta)分布采样转换成单位圆的采样 而单位球上的均匀采样正好也满足同样的概率分布 如何提高积分器的效率 https://zhuanlan.zhihu.com/p/82984446 通过构造一个近似原被积函数的新函数的解析积分方法。 通过在积分域中合理分布采样点。 通过在采样过程中获得的信息适应性控制采样密度。 通过结合来自不同估计的结果。 efficiency of an estimator variance time Russian Roulette and Splitting Russian Roulette 目标是无偏地 skip tracing unimportant rays. 通常c=0 但是问题是Russian Roulette会增大方差。 splitting increases the number of samples taken in order to improve efficiency Careful Sample Placement 讨论了减少方差的一些方法 Stratified Sampling 基本原理就是把积分区域分成n nonoverlapping regions, 在每个region里再进行采样。 Quasi Monte Carlo they replace the pseudo-random numbers used in standard Monte Carlo with low-discrepancy point sets generated by carefully designed deterministic algorithms. 引入bias 改成有偏估计但是方差更小 Importance Sampling 采样的概率密度分布尽可能的接近原函数。 eg. if directions are sampled from distributions that match other factors of the integrand (the BSDF, the incoming illumination distribution, etc.), efficiency is similarly improved. 一个粗糙的证明： Multiple Importance Sampling 多个函数相乘的积分估计是更加困难的，因为不是简单的分别采样就可以得到一个好的结果，有的时候错误的分布采样得到的结果甚至比随机均匀采样还要糟糕。 Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-08-01 18:43:58 "},"ray_tracing/denoising/resource.html":{"url":"ray_tracing/denoising/resource.html","title":"Denoising and Filtering","keywords":"","body":"Resources non-DL based denoising REBLUR REBLUR, ray tracing gems 2 chapter 49: A Hierarchicle Recurrent Denoiser REBLUR GTC2020 talk SVGF SVGF: Spatiotemporal Variance-Guided Filtering ReLAX: A Denoiser Tailored to Work with the ReSTIR Algorithm ReLAX originates from SVGF but takes image quality and performance to the next level. DL based denoising Kernel-Predicting Convolutional Networks for Denoising Monte Carlo Renderings Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-09-11 16:36:01 "},"ray_tracing/intersection_acceleration/resource.html":{"url":"ray_tracing/intersection_acceleration/resource.html","title":"Intersection Acceleration Structure","keywords":"","body":"Resources BVH SDF HZB Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-02-08 11:50:44 "},"ray_tracing/intersection_acceleration/bvh/bvh.html":{"url":"ray_tracing/intersection_acceleration/bvh/bvh.html","title":"BVH and KdTree","keywords":"","body":"PBR Primitives and Intersection Acceleration basic thoughts BVH basic principle BVH construction ways middle equal counts surface area heuristic (SAH) linear bounding volume hierarchies compact BVH traversal Kd-Tree BSP and kd-tree tree representation tree construction basic thoughts spatial subdivision ---- kdTree object subdivision ---- BVH object subdivision is based on progressively breaking the objects in the scene down into smaller sets of constituent objects. BVH basic principle 根据object的bounding box分布，把物体划分成树的结构。 BVH construction ways middle choose the partition axis has the largest range of the centroids of the primitives’ bounding boxes split primitives based on the midpoint of centroid on chosen axis equal counts split primitives based on mid count of sorted centroid on chosen axis surface area heuristic (SAH) based on cost probability based on surface area（bounding box 的表面积） each primitive is placed in a bucket along the axis based on the centroid of its bounds cost each cost for each bucket boundary 这里假设，遍历树的cost是0.125，树节点求相交的cost是1.0 linear bounding volume hierarchies Mortan code 把各个维度的坐标(整数值)转换成2进制编码 Mortan编码的好处是，index接近或者说高bit位相同的分布在临近的区域 hierarchical linear bounding volume hierarchy (HLBVH) 低层次的树采用Morton-curve-based clustering，高层次的树采用surface area heuristic 简单的说用Morton来做各个分桶里的BVH，用SAH做桶的BVH 计算所有primitives的centroid的boundingbox 计算每个primitive的centroid的Mortan code x, y, z每个维度计算相对于所有centroid的bdbox的offset，归一化到[0, 1]. 每个维度用10个bit编码，归一化的offset乘以2^10取整编码。 通过多次移位编码成Mortan code 每6个bit一起做sort 前12个bit开始构建BVH 根据前12个bit分线程，然后依次根据下一个bit进行分支构建节点，根据bit位不同进行分支 for前12个bit的桶进行SAH BVH构建 compact BVH 深度优先 每个左节点会记录下兄弟节点的offset traversal 从root节点开始判断 for more efficiently, 根据ray相对于axis的朝向决定优先和左子节点还是右子节点求交 Kd-Tree BSP and kd-tree Binary space partitioning (BSP) trees adaptively subdivide space with planes. Two variations of BSP trees are kd-trees and octrees. tree representation tree construction built with a recursive top-down algorithm Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-10-05 10:54:16 "},"volume/resource.html":{"url":"volume/resource.html","title":"Volume Rendering","keywords":"","body":"Resources Production Volume Rendering SIGGRAPH 2017 Course 将volume rendering加入到path tracing中，目前只看了volume rendering的理论知识部分，讲的挺好的 siggraph15, Frostbite Physically-based & Unified Volumetric Rendering Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-03-21 18:04:44 "},"volume/volume_rendering/volume_rendering.html":{"url":"volume/volume_rendering/volume_rendering.html","title":"Volume Rendering Basic Theory","keywords":"","body":"Volume Rendering Basic Theory Volume Rendering Basic Theory properties of volumes light propagation in volumes discrete methods properties of volumes what are volumes Volumes, are collections of particles, ranging from atoms and molecules to any particle size. collision probability the chance of a photon collision probability density of collision per unit distance deﬁned by a coeﬃcient σ(x), which is the probability density of collision per unit distance traveled inside the volume. The physical unit of a collision coeﬃcient is inverse length. mean free path the average distance traveled between collisions. light propagation in volumes radiative transformation equation(RTE) what happens to a radiance beam as it travels forward absorption out-scattering emission in-scattering RTE Volume Rendering Equation(VRE) describes the radiance in terms of where it comes from discrete methods 积分转换成离散求和，沿一个方向ray marching来累积。 这部分待推导 Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2023-06-12 11:34:23 "},"LI/resource.html":{"url":"LI/resource.html","title":"LI","keywords":"","body":"Resources Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-10-05 10:45:21 "},"LI/li_summary/li.html":{"url":"LI/li_summary/li.html","title":"Real-Time LI Summary","keywords":"","body":"Real-Time Local Illumination Summary Background Area Light Sources Glossy Materials Mittring’s roughness modiﬁcation Representative Point Technique General Light Shapes tube lights (capsules) card lights planar polygonal area lights Environment Lighting Ambient Light Spherical and Hemispherical Functions Simple Tabulated Forms Spherical Bases Basic Ideas Spherical Radial Basis Functions Spherical Gaussians Spherical Harmonics Other Spherical Representations Hemispherical Bases Ambient/Highlight/Direction (AHD) Basis Radiosity Normal Mapping/Half-Life 2 Basis Hemispherical Harmonics(HSH)/H-Basis Environment Mapping Definition Reﬂection mapping Mapping Latitude-Longitude Mapping Sphere Mapping Cube Mapping Other Projections Specular Image-Based Lighting Ideas Preﬁltered Environment Mapping Convolving the Environment Map Split-Integral Approximation for Microfacet BRDFs Asymmetric and Anisotropic Lobes Irradiance Environment Mapping Spherical Harmonics Irradiance Other Representations Sources of Error Background In reality, lighting is never punctual. The sky is an important source of light, caused by sunlight scattering from the atmosphere. In order to form a more realistic lighting model, we need to integrate the BRDF response over the full hemisphere of incident directions on the surface. In offline rendering, usually averaging multiple samples(rays) In real-time rendering, we will need to approximate the light emitter, the BRDF, or both. Area Light Sources Vector Radiance Wrap LightingGlossy Materials uniformly emitting spherical area lights and arbitrary glossy BRDFsMittring’s roughness modiﬁcation Mittring, Martin, “The Technology Behind the ‘Unreal Engine 4 Elemental Demo’,” Game Developers Conference, Mar. 2012. Approximate the convolution between the light source and the material BRDF by ﬁnding a new BRDF lobe, of a diﬀerent roughness, that has a corresponding cone whose solid angle is equal to the sum of the light lobe angle and the material one. roughness clamp cause artifacts Representative Point Technique Represent the area illumination’s source with a light direction that changes based on the point being shaded These approaches resemble the idea of importance sampling in Monte Carlo integration, where we numerically compute the value of a deﬁnite integral by averaging samples over the integration domain. In order to do so more eﬃciently, we can try to prioritize samples that have a large contribution to the overall average. mean value theorem of definite integrals General Light Shapes tube lights (capsules) card lights Drobot, Michal, “Physically Based Area Lights,” in Wolfgang Engel, ed., GPU Pro 5, CRC Press, pp. 67–100, 2014. Cited on p. 116, 388 representative point solution planar polygonal area lights Heitz, Eric, Jonathan Dupuy, Stephen Hill, and David Neubelt, “Real-Time Polygonal-Light Shading with Linearly Transformed Cosines,” ACM Transactions on Graphics (SIGGRAPH 2016), vol. 35, no. 4, pp. 41:1–41:8, July 2016. Cited on p. 390 key idea of LTC 把不同的BRDF和simple cosine BRDF做转换 Environment Lighting Methods to integrate radiance deﬁned by a varying function over all the possible incoming directions. Ambient Light the radiance does not vary with direction and has a constant value Spherical and Hemispherical Functions spherical bases properties in a given basis Simple Tabulated Forms pick several directions and store a value for each encode many diﬀerent spherical functions with arbitrarily low error by adding more samples as needed samples to choose Spherical Bases Basic Ideas ways to project (encode) functions onto representations that use a ﬁxed number of values (coeﬃcients) basic example one kind of most minimal possible base --- constant two coefficients a more complex example Spherical Radial Basis Functions radially symmetric makes the function only one argument a set of functions called lobes spread across the sphere projection and reconstruction Spherical Gaussians definition A proper basis is obtained only when we choose a ﬁxed set of lobes (directions and spreads), so that the entire domain is well covered, and perform projection by ﬁtting only the weights w_k. The optimization problem is formulated as ordinary least-squares optimization. production and integration anisotropic spherical guassians Spherical Harmonics Spherical harmonics (SH) are an orthogonal set of basis functions over the sphere. orthogonal means that the inner product of any two diﬀerent functions from the set is zero projection A function space has an inﬁnite number of dimensions, so a ﬁnite number of basis functions can never perfectly represent it. frequency bands integral In this spectral domain, the integral of the product of two functions is equal to the dot product of the coeﬃcients of the function projections. Other Spherical Representations linearly transformed cosines spherical wavelets Hemispherical Bases half of the signal the BRDF, the incoming radiance, and the irradiance arriving at given point of an object Ambient/Highlight/Direction (AHD) Basis a constant ambient light ---- ambient direction and color a single directional light that approximates the irradiance in the “highlight” direction ---- highlight direction the direction where most of the incoming light is concentrated ----- incoming direction and color projection Precomputed Lighting in Call of Duty: Inﬁnite Warfare,” SIGGRAPH Advances in Real-Time Rendering in Games course, Aug. 2017 signal is ﬁrst projected to spherical harmonics, and the optimal linear direction is used to orient the cosine lobe Radiosity Normal Mapping/Half-Life 2 Basis represents hemispherical functions on surfaces by sampling three directions in tangent space projection and reconstruction Hemispherical Harmonics(HSH)/H-Basis Zernike polynomials H-basis Habel, Ralf, and Michael Wimmer, “Eﬃcient Irradiance Normal Mapping,” in Proceedings of the 2010 ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games take part of the spherical harmonic basis for the longitudinal parameterization and parts of the HSH for the latitudinal one Environment Mapping Definition Recording a spherical function in one or more images is called environment mapping, as we typically use texture mapping to implement the lookups in the table. How well we can integrate environment lighting with given materials. A variety of projector functions that map the reﬂected view vector into one or more textures. Reﬂection mapping assume that the BRDF is a perfect mirror calculation Mapping Latitude-Longitude Mapping spherical coordinates ( ρ , φ ). Here φ , equivalent to the longitude, varies from 0 to 2π radians, and ρ , the latitude, varies from 0 to π radians. problem the density of information is nowhere near uniform the areas near the poles receive many more texels than those near the equator result in artifacts when employing hardware texture ﬁltering especially visible at the two pole singularities transcendental functions such as arccosine are costly on GPUs Sphere Mapping in sphere map's space, view vector is always (0, 0, 1) maps each reﬂected view direction to a point on the two-dimensional image of this sphere derive the surface normal(view space) on the sphere, which will then yield the (u, v) parameters needed to access the sphere map much simpler to compute one singularity located around the edge of the image circle valid for only a single view direction Cube Mapping created by projecting the environment onto the sides of a cube positioned with its center at the camera’s location its projection is implemented directly in hardware on modern GPUs view-independent much more uniform sampling characteristics modern GPUs can now correctly perform this ﬁltering across edges Other Projections dual paraboloid environment mapping more uniform texel sampling of the environment compared to the sphere map and the cube map take care for proper sampling and interpolation at the seam between the two projections which is expensive Octahedral(八面体) mapping projection Given a reﬂection direction r no ﬁltering issues as the seams of the parameterization correspond with the edges of the texture used Radially-Symmetric Reﬂection Maps a simple factorization using a single one-dimensional texture storing the radiance values along any meridian line from the symmetry axis Specular Image-Based Lighting Ideas blurring the environment map texture to simulate surface roughness consider the shape a BRDF function at least ﬁve dimensions of input values (roughness and two polar angles each for the view and normal directions) that control the resulting lobe shape indexed with the reﬂected view vector which contain radiance values Preﬁltered Environment Mapping To accommodate for diﬀerent roughness levels, it is common to employ the mipmaps of an environment cube map. Each level is used to store blurred versions of the incoming radiance, with higher mip levels storing rougher surfaces. Convolving the Environment Map Split-Integral Approximation for Microfacet BRDFs many techniques have been developed to lessen the BRDF approximation issues inherent in cube map preﬁltering split-integral approximation the ﬁrst depends only on surface roughness and the reﬂection vector, with the assumption of a radial symmetric D lobe in practice, we can use any lobe, imposing n = v = r the second integral is the hemispherical-directional reﬂectance of the specular term depends on the elevation angle θ, roughness α, and Fresnel term F (F0) Asymmetric and Anisotropic Lobes uses a single sample, but tries to ﬁnd the best lobe to approximate the BRDF in the current view direction instead of relying on a constant correction factor better simulates surfaces at grazing angles averages several samples from diﬀerent lobes include the stretched highlights typical of half-vector models Irradiance Environment Mapping indexed with just the surface normal n, and they contain irradiance values for each texel in the map, we need to sum up the cosine-weighted contributions of all illumination aﬀecting a surface facing in a given normal direction stored and accessed separately from the specular environment or reﬂection map, usually in a view-independent representation such as a cube map Spherical Harmonics Irradiance cause irradiance from environment lighting is smooth convolving radiance with a cosine lobe results in the removal of all the high-frequency components from the environment map an accuracy of about 1% with just the ﬁrst nine SH coeﬃcients (each coeﬃcient is an RGB vector, so we need to store 27 ﬂoating point numbers) SH projection dynamic light sources can be added into an existing SH irradiance environment map Other Representations many irradiance environment maps have two dominant colors: a sky color on the top and a ground color on the bottom hemisphere lighting model the upper hemisphere is assumed to emit a uniform radiance L_sky the lower hemisphere is assumed to emit a uniform radiance L_ground where θ is the angle between the surface normal and the sky hemisphere axis a faster approximation wavelet representations Sources of Error employing a mix of techniques for lighting means that we are working with approximations BRDF model that have varying degrees of error make sure that the discrepancies between diﬀerent forms of lighting are not evident occlusions are also of key importance for realistic rendering, as light “leaking” where there should be none is often more noticeable than not having light where it should be assume inﬁnitely distant radiance sources, ones that are never possible assume the lights emit radiance uniformly over the outgoing hemisphere for each point on their surface Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-10-05 10:42:01 "},"GI/resource.html":{"url":"GI/resource.html","title":"GI","keywords":"","body":"Resources contents note GI draft 真的是从啥也不会开始初步的了解各个算法流派以及现有的resolution，只能当成是一个简单的目录索引去看，涉及到的算法细节其实没有完全搞清楚。列举了每种算法的基本原理和相应resolution以及各自的优缺点，真的是非常小学生的“调研报告”了。 Precomputed Based GI 基于预计算的GI. Voxel Based GI 基于体素的GI, 包括了算法原理的笔记，demo实现的记录等。 books 秦春林 的 全局光照技术 涉及到的GI算法比较全，且是中文的，看起来比较没有那么费力 lessons 闫令琪的Games201课程 Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-07 21:04:04 "},"GI/GI_draft/GI_draft.html":{"url":"GI/GI_draft/GI_draft.html","title":"GI Draft","keywords":"","body":"GI draft 什么是GI 先验知识 radiometry render equation 主要思路 最直观的思路 ——— ray tracing type 把耗费性能的计算提前处理 ——— precomputed type 减少光照计算的geometry粒度 GI data的存储 基本流派 ray tracing basic theory solutions photon mapping basic theory solutions instant radiosity solutions Light Propagation Volumes GI basic theory solutions radiosity basic theory solutions voxel based basic theory solutions screen space GI basic theory solutions GI数据存储 现有的解决方案 Enlighten features 优点 缺点 NVDIA　VXGI features CryEngine SVOGI features Current Limitations DXR GI 优点 缺点 UE4 LPV features 什么是GI Global illumination (GI) is a family of algorithms that simulate how light interacts and transfers between objects in a scene. 简单的理解就是 GI = direct lighting + indirect lighting, 产生包括漫反射，高光，镜面反射，散射，焦散，阴影等效果。 Direct lighting较为简单，所以以下的技术主要都是针对indirect lighting的计算。 先验知识 radiometry radiant energy & radiant flux radiant intensity 每单位立体角上的radiant flux irradiance 每单位照射面积所接收到的radiant flux radiance 每单位立体角，每单位垂直面积的radiant flux. render equation basic equation a kind of BRDF extension 主要思路 最直观的思路 ——— ray tracing type tracing from camera tracing from light tracing from both camera and light photon mapping instant radiosity 把耗费性能的计算提前处理 ——— precomputed type 对光照传输过程进行预计算 precompute各个方向的入射光radiance environment map precompute irradiance即各个方向入射光radiance的积分值 prefiltering precompute 可见性和入射光余弦项对应的积分 PRT 对光照结果进行预计算 precompute除去Kd和Ks剩余积分项 减少光照计算的geometry粒度 把场景的表面细分成一些粒度较大的面片 radiosity 计算场景中空白位置的光照信息，物体的光照由这些位置的结果计算 light probe 把3d空间划分成一些子集，以子集的光照信息作为代表 voxel 将计算限制在屏幕空间 screen space GI GI data的存储 lightmap cubemap spherical harmonics spherical guassian 基本流派 ray tracing basic theory path tracing 基本算法步骤 选择一个光线，给定参数（x,y,u,v,t） 找到与这个光线最近的一个表面交点处 随机决定是否计算发射(emitted)或反射(reflected)光。 如果计算发射光：返回 weight Le。 如果计算反射光：weight = reflectance，BRDF pdf随机散射，返回第二步。 算法在path到达光源时终止。 solutions DXR GI frosbite photon mapping basic theory 基本算法步骤 构造photon map 光子从光源发射到场景中。一旦光子和一个几何面相交，相交点和入射方向就会被存在一个叫光子贴图（photon map）的缓存中。 利用photon map计算辐射度 用nearest neighbor搜索函数搜索光子贴图，收集临近区域的N个光子 构造一个球体S，把得到的这N个光子包围起来 对每个光子，根据S和BRDF，计算其光通量能量 所有光子的贡献总和将为相交点的辐射强度 三种类型的photon map caustics photon map global photon map volume photon map solutions real-time GI with photon mapping instant radiosity basic theory 基本算法步骤 从光源上产生N个粒子 从光源打出很多light sub-path，这些光会停在某些地方，就认为它停在的地方就变成了新的虚拟点光源光源（VPL) VPLs可以存在一张Reflective Shadow Map(RSM)中 用新的VPL计算光照 可以采用光栅化，ray tracing或是其他方法。 solutions Instant Radiosity for Real-Time Global Illumination Light Propagation Volumes GI basic theory 本质上是instant radiosity结合radiance volume的思想。 基本的算法步骤 solutions UE4 : LPV CryEngine radiosity basic theory 基本的算法步骤 对场景的表面进行曲面细分 计算两两曲面之间的form factors 求解radiosity matrix(迭代法) 初始数据为直接光照结果 计算每个pixel的光照 incremental radiosity会在材质或者物体位置等发生变化时动态更新form factors和radiosity solutions frosbite 2010 enlighten voxel based basic theory 基本的算法步骤 将场景体素化 构建数据结构 SVOGI 构建八叉树管理体素 VXGI 构建clipmap 对体素的着色参数进行预过滤 cone tracing visibility 25%=50% x 50% reference 腾讯游戏学院 知乎 简单的实现 solutions VXGI CryEngine : Sparsed Voxel-based Global Illumination (SVOGI) screen space GI basic theory SSDiffuse 基本的算法步骤 1.采样不同lod的深度图信息并得到其中最大的深度值。（要执行多少次寻找就看你设置多少次pass） 2.用ray marching的方式，并用噪音图采样以圆的周长来找周围的像素点的颜色，这个颜色是根据当前场景颜色做的（所以ssgi一般放到最后处理）。采样的点存储到rt上 3.这时的rt是带有比较明显的锯齿的rt，需要用taa方式过滤一次 4.最后在横向和纵向做两次模糊处理。 5.这样就得到了ssgi的漫反射方向的间接光照了，最后只需要把场景图和这个间接光rt combine一下就好了。 SSR solutions UE4 SSGI GI数据存储 light maps spherical harmonics Spherical harmonics from offline photon mapper Texel has irradiance at surface point, as a continuous function on a sphere Probes for dynamic objects also stored as SHs SH: Great for diffuse, but specular 适合存储低频的信息 spherical guassian Approximate incoming radiance using spherical gaussians Intuitive & compact representation for diffuse and specular Probes for dynamic objects also stored as SGs Extensive implementation details on Matt’s blog [Pettineo16] 现有的解决方案 Enlighten Enlighten calculates the effect of global illumination in real-time. Lights, materials and objects can be moved and updated at runtime with the global illumination updating in milliseconds. Enlighten makes use of both lightmaps and light probes to enable efficient rendering. Probes makes lighting of complex meshes with very many small features, such as foliage, are more efficiently lit using probes. features light maps and light probes iterate fast Enlighten continuously updates global illumination in the background dynamic world outdoor, innerdoor... real-time reflections, even for off-camera objects emissive surfaces will have almost zero performance cost 优点 独立的SDK 支持多个平台, mobile, pc, console, VR 比较成熟的商业化产品，迭代解决了很多问题 缺点 CPU计算，因此免不了在GPU-CPU之间更新数据 enlighten不能够很好处理场景被破坏，结构改变等时候的光照变化情况 贵！！ NVDIA　VXGI It provides means to quickly compute a voxel representation of a mesh scene and use that representation with Voxel Cone Tracing for diffuse and specular global illumination, ambient occlusion, and high-quality area lighting. features Indirect diffuse and specular interreflections High-quality planar area lights with soft shadows Large-scale, stable ambient occlusion Dynamic and procedural geometry Dynamic lights and emissive materials Virtual Reality support, including MRS and LMS CryEngine SVOGI features Dynamic indirect light bounce from static and most of dynamic objects. Large scale AO and indirect shadows from static geometry (vegetation, brushes and terrain). Works without pre-baking and does not require manual setup of many bounce lights or light volumes. Current Limitations Large scale AO and indirect shadows may be cast properly only by static geometry. GI is not working on some forward rendering components like particles or water. Some artifacts like ghosting, aliasing, light leaking and noise may be noticeable in some cases. Procedural vegetation and merged vegetation do not cast occlusion or secondary shadows. If the camera is teleported to a completely new location it may take up to a few seconds until occlusion is working properly. Only objects and materials with enabled shadow map casting may produce proper bounced light. For dynamic objects indirect light bounce is working only in the areas near voxelized static geometry. Bounce light may have a noticeable delay of 1-2 frames. r_Supersampling = 2 makes GI look strange but setting lower LowSpecMode (2X lower) pretty much restores the look and speed. Temporal AA (r_AntialiasingMode 2/3) works just fine. DXR GI provides scalable solutions to compute multi-bounce indirect lighting without bake times, light leaks, or expensive per-frame costs. 优点 室内外及室内。RTX可避免漏光。 游戏运行时。RTX GI可保障性能，可跨GPU扩展，分辨率高达4K，且无噪点。 游戏制作。RTX GI可告别烘焙耗时，无需每探头调优，并能够加速当前光照探针工作流程和专业度的提升。 任何光照类型：RTX GI可针对点、线、面积照明、天空盒照明和发光物体自动展开工作。 引擎：RTX GI可升级现有光照探针引擎数据路径和工具。 内容创建：RTX GI采用完全动态的场景，无需人工干预。 可扩展性：一条代码路径即可实现所有，从能够避免旧有遗留平台漏光现象的烘焙光照探针，价格较低的GPU上慢慢更新的运行时GI，到发烧友级GPU上的即时动态GI。它能够在发挥高端PC强大功能的同时提供广泛的支持。 缺点 每个级联5MB GPU RAM，所有级联和中间层峰值均为20MB 在固定时间模式下，1-2毫秒/帧可获最佳性能，在超高固定画质模式下，1-2 Mray/帧可获最佳性能（在2080 Ti上亦如此） 在针对其他效果（如光面和阴影光线）使用光线追踪时，可最大限度地减少开销。 在画面开发和制作早期就应引入RTX GI。GI能够极大程度上改变光照，比直射光需要更多符合物理原理的几何图形和调优，也为游戏领域带来了全新机遇。 基于低端GPU则光照流速较慢（世界-空间延迟，无屏幕-空间重影） 阴影图类的偏置参数必须调优至场景比例。 无法防止零厚度/单面墙漏光 必须与另外的光面全局照明解决方案（如屏幕-空间光线追踪、去噪几何光线追踪或环境探针）配合使用。 UE4 LPV features Computed each frame which allows dynamic material/light/geometry. Diffuse and approximated specular material interaction. Limited distance (larger volume e.g. 2x would be easy but memory requirements and some computations would grow by 8x). Constant detail in world space (it would be better to have more detail nearby and less detail in distance). Not affecting translucency. Light bounce is not affected by decals. Decal shading just works (unlike with baked lighting where the lighting is applied in the base pass before decals get applied). Requires compute shader (DirectX 11) support. Supports one or more Directional light for light bounce. Changing the size at runtime has minor artifacts that fade away over time. Emissive lighting for cheap area lights (not currently implemented). Occlusion (not currently implemented). Point light shadows approximated by occlusion (not currently implemented). Secondary occlusion through geometry voxelization which has some performance cost but quite better quality (not currently implemented). 杂 Ray tracing 光线追踪 Path tracing 路径追踪 Photon mapping 光子映射 Point Based Global Illumination 基于点的全局光照 Radiosity 辐射度 Metropolis light transport 梅特波利斯光照传输 Spherical harmonic lighting 球谐光照 Spherical Gaussian lightmaps Ambient occlusion 环境光遮蔽 Voxel-based Global Illumination 基于体素的全局光照 Light Propagation Volumes Global Illumination Deferred Radiance Transfer Global Illumination Deep G-Buffer based Global Illumination screen space GI RRS category 1 : features diffuse GI specular GI ambient occlusion area lighting category 2 precompute lighting precomputed radiance transfer real-time Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-03-07 16:19:08 "},"GI/ssgi/resource.html":{"url":"GI/ssgi/resource.html","title":"SSGI","keywords":"","body":"Resources SSR SSGI theory 14, Efficient GPU Screen-Space Ray Tracing sig15, frosbite, Stochastic Screen-Space Reflections sig17, Optimized pixel-projected reflections for planar reflectors GPU pro, Hi-Z Screen-Space Cone-Traced Reflections implementations unity stochastic SSR unity tick SSGI compute stochastic SSR AMD Stochastic SSR Xerxes1138, stochastic SSR Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-09-08 10:13:50 "},"GI/ssgi/UE_SSR.html":{"url":"GI/ssgi/UE_SSR.html","title":"UE SSR Implementation","keywords":"","body":"UE SSR Realization pre frame reduction 用来生成mip map的source texture 都是上一帧的depth 和 color 判断是否计算天空 depth color and alpha tile-based classification 分组 classification ray discard deal with gbuffer data SSR quality importance sampling half vector incident light jitter InterleavedGradientNoise 作为step_offset ray marching transform a ray for screen space ray casting ray marching hit result pre frame reduction SSRTPrevFrameReduction.usf 用来生成mip map的source texture 都是上一帧的depth 和 color 根据screen space 的 velocity 计算上一帧的uv float4 EncodedVelocity = GBufferVelocityTexture.SampleLevel(GBufferVelocityTextureSampler, SceneBufferUV, 0); if (EncodedVelocity.x > 0.0) { PrevScreen = ThisClip.xy - DecodeVelocityFromTexture(EncodedVelocity).xy; } mip map level = 5 第一个pass生成mip map level 0-1 level 0 就直接是pre frame 的color texture的下一级采样了，等于不再浪费一个level去存原始的color值，这难道就是传说中的SSR在half resolution里做。 这里的操作很骚气，每个pass最多只生成3个level，第一个pass只生成2个level，所以只输出最后2个color_output。 第二个pass生成mip map level 2-4判断是否计算天空 bool bIsSky = WorldDepth > SkyDistance && SkyDistance > 0.0; depth 取了最大，这个有点奇怪，按理说不是最小的depth么？ 并不是在这个pass生成的hi-z, 但是也是取了四个pixel中的最大depth。 后来看了下，应该是做SSRT的时候用的是minimum depth，这里计算权重的时候还是用了最大的depth. color and alpha alpha应该是为半透明物体的渲染时用的。 其实这里看实现真的有点诡异的。 取前一帧的原color值时 这里是根据uv和depth反算出世界坐标，然后计算到上一级的世界坐标的平方，再除以radius平方来作为weight的，讲道理这四个weight加一起也不一定是1，这样直接加权会不会有问题。 float WorldDepthToPixelWorldRadius = GetTanHalfFieldOfView().x * View.ViewSizeAndInvSize.z * 100; // 这边的100倍是随意弄出来的，还是有啥含义额 // 这里的radius计算也是有点迷，不太理解这是什么含义，这里是拿world_depth / near_plane_depth么 float WorldBluringRadius = WorldDepthToPixelWorldRadius * WorldDepth; float InvSquareWorldBluringRadius = rcp(WorldBluringRadius * WorldBluringRadius); float2 SampleUV = PrevFrameUV; // + View.BufferSizeAndInvSize.zw * (float2(i % 2, i / 2) - 0.5); SampleUV = clamp(SampleUV, PrevBufferBilinearUVMinMax.xy, PrevBufferBilinearUVMinMax.zw); float PrevDeviceZ = PrevSceneDepth.SampleLevel(PrevSceneDepthSampler, SampleUV, 0).r; float3 SampleWorldPosition = ComputeTranslatedWorldPosition(PrevScreen.xy, ConvertFromDeviceZ(PrevDeviceZ), /* bIsPrevFrame = */ true); float SampleDistSquare = length2(RefWorldPosition - SampleWorldPosition); float SampleWeight = saturate(1 - SampleDistSquare * InvSquareWorldBluringRadius); PrevColor = float4(PrevSceneColor.SampleLevel(PrevSceneColorSampler, SampleUV, 0).rgb * SampleWeight, SampleWeight); mip map level 0-4 这里的权重计算方式跟上面还不一样，是直接用depth相减然后除以radius平方，最后还除以一个4，这是什么骚操作额，看不懂，难道是因为不好再反计算world position了，总之感觉有点怪。 UNROLL for (uint x = 0; x tile-based classification 搜了下感觉这个代码是不是废弃了，并没有人调用，看逻辑感觉也有点诡异。 SSRTTileClassification.usf & SSRTTileClassificationBuffer.ush 分组 8x8个像素为一个tile，每个tile分成8个方向去计算。取8x8中的(4,4)位置作为代表计算。 // GROUP_TILE_SIZE 8 // SSRT_DIRECTIONALITY_DIVISION 8 [numthreads(GROUP_TILE_SIZE, GROUP_TILE_SIZE, SSRT_DIRECTIONALITY_DIVISION)] uint2 TileCoord = DispatchThreadId; uint DirectionId = GroupThreadId.z; float2 ViewportUV = (TileCoord * GROUP_TILE_SIZE + GROUP_TILE_SIZE / 2) * View.ViewSizeAndInvSize.zw; float DirectionAndle = float(DirectionId) * (2 * PI * rcp(float(SSRT_DIRECTIONALITY_DIVISION))); classification 讲道理这边应该用furthest depth. 计算screen space 下的 start, direction, end float2 RayStartScreen = ViewportUVToScreenPos(ViewportUV); float2 RayStepScreen = normalize(View.ViewSizeAndInvSize.zw * RayPixelDirection); RayStepScreen *= GetStepScreenFactorToClipAtScreenEdge(RayStartScreen, RayStepScreen); float2 RayEndViewportUV = ScreenPosToViewportUV(RayStartScreen + RayStepScreen); float2 RayStartPixel = ViewportUV * View.ViewSizeAndInvSize.xy; float2 RayEndPixel = RayEndViewportUV * View.ViewSizeAndInvSize.xy; float MaxSampleDistance = length(RayStartPixel - RayEndPixel); ray marching 每个方向走五步，步子越来越大，每一步计算周围的最小depth，除以delta_width, 计算一个最大的角度，存储这个最大的角度和tile代表pixel的最小depth. 这个有啥参考价值么，思路感觉有点怪呀~ ray discard 根据之前计算的最大角度去剔除一些ray marching direction. bool TestRayEarlyReturn(FSSRTTileInfos TileInfos, FSSRTRay Ray) { float2 RayStepPixel = Ray.RayStepScreen.xy * View.ViewSizeAndInvSize.xy; float DeltaU = length(RayStepPixel) * (0.5 * View.ViewSizeAndInvSize.z); float DeltaZ = Ray.RayStepScreen.z; float RayTheta = atan2(DeltaU, -DeltaZ); uint DirectionId =ComputeRayDirectionId(Ray); bool bEarlyReturn = RayTheta > TileInfos.Directionality[DirectionId]; return bEarlyReturn; } deal with gbuffer data roughness 这一步是为了啥？？ float GetRoughnessFade(in float Roughness) { // mask SSR to reduce noise and for better performance, roughness of 0 should have SSR, at MaxRoughness we fade to 0 return min(Roughness * SSRParams.y + 2, 1.0); } SSR quality different quality 决定 num of steps num of rays b_glossy ?? 只 trace 一条光线的时候 是否用 GGX importance sampling #if SSR_QUALITY == 1 uint NumSteps = 8; uint NumRays = 1; bool bGlossy = false; #elif SSR_QUALITY == 2 uint NumSteps = 16; uint NumRays = 1; #if SSR_OUTPUT_FOR_DENOISER bool bGlossy = true; #else bool bGlossy = false; #endif #elif SSR_QUALITY == 3 uint NumSteps = 8; uint NumRays = 4; bool bGlossy = true; #else // SSR_QUALITY == 4 uint NumSteps = 12; uint NumRays = 12; bool bGlossy = true; #endif importance sampling half vector GGX of visible normal GGX ```cpp float3x3 TangentBasis = GetTangentBasis( N ); float3 TangentV = mul( TangentBasis, V ); float2 E = Hammersley16( i, NumRays, Random ); float3 H = mul( ImportanceSampleVisibleGGX(UniformSampleDisk(E), roughnessroughness, TangentV ).xyz, TangentBasis ); float3 L = 2 dot( V, H ) * H - V; ```cpp // [ Heitz 2018, \"Sampling the GGX Distribution of Visible Normals\" ] // http://jcgt.org/published/0007/04/01/ // PDF = G_SmithV * VoH * D / NoV / (4 * VoH) // PDF = G_SmithV * D / (4 * NoV) float4 ImportanceSampleVisibleGGX( float2 DiskE, float a2, float3 V ) { // NOTE: See below for anisotropic version that avoids this sqrt float a = sqrt(a2); // stretch float3 Vh = normalize( float3( a * V.xy, V.z ) ); // Orthonormal basis // Tangent0 is orthogonal to N. #if 1 // Stable tangent basis based on V. float3 Tangent0 = (V.z > 16 ) ^ Random.y ) * (1.0 / 65536.0); return float2( E1, E2 ); } float2 UniformSampleDisk( float2 E ) { float Theta = 2 * PI * E.x; float Radius = sqrt( E.y ); return Radius * float2( cos( Theta ), sin( Theta ) ); } // [ Duff et al. 2017, \"Building an Orthonormal Basis, Revisited\" ] // Discontinuity at TangentZ.z == 0 float3x3 GetTangentBasis( float3 TangentZ ) { const float Sign = TangentZ.z >= 0 ? 1 : -1; const float a = -rcp( Sign + TangentZ.z ); const float b = TangentZ.x * TangentZ.y * a; float3 TangentX = { 1 + Sign * a * Pow2( TangentZ.x ), Sign * b, -Sign * TangentZ.x }; float3 TangentY = { b, Sign + a * Pow2( TangentZ.y ), -TangentZ.y }; return float3x3( TangentX, TangentY, TangentZ ); } incident light cos hemisphere uniform concentric disk jitter InterleavedGradientNoise 作为step_offset // high frequency dither pattern appearing almost random without banding steps //note: from \"NEXT GENERATION POST PROCESSING IN CALL OF DUTY: ADVANCED WARFARE\" // http://advances.realtimerendering.com/s2014/index.html // Epic extended by FrameId // ~7 ALU operations (2 frac, 3 mad, 2 *) // @return 0..1 float InterleavedGradientNoise( float2 uv, float FrameId ) { // magic values are found by experimentation uv += FrameId * (float2(47, 17) * 0.695f); const float3 magic = float3( 0.06711056f, 0.00583715f, 52.9829189f ); return frac(magic.z * frac(dot(uv, magic.xy))); } ray marching transform a ray for screen space ray casting 计算一条ray的world space的 start 和 end point 将world space 下的 start 和 end 转换到 screen space --> RayStartScreen 计算screen space下的trace direction --> RayStepScreen 计算 CompareTolerance 是做啥的 ？？？ FSSRTRay InitScreenSpaceRayFromWorldSpace( float3 RayOriginTranslatedWorld, float3 WorldRayDirection, float WorldTMax, float SceneDepth, float SlopeCompareToleranceScale, const bool bExtendRayToScreenBorder, out bool bRayWasClipped) { WorldTMax = min(WorldTMax, 1000000); float3 ViewRayDirection = mul(float4(WorldRayDirection, 0.0), View.TranslatedWorldToView).xyz; float RayEndWorldDistance = ViewRayDirection.z ray marching mip map levelLevel += (8.0 / NumSteps) * Roughness; 四个step作为一把batch一起算 计算hit的时候用二分法，还用了前后两步插值 hit result 所有rays的结果累加求平均 剩下的是在做啥呦OutColor.rgb *= rcp( 1 - Luminance(OutColor.rgb) ) OutColor *= RoughnessFade; OutColor *= SSRParams.r; Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-10-05 11:24:53 "},"GI/ssgi/ppr/ppr.html":{"url":"GI/ssgi/ppr/ppr.html","title":"Optimized Pixel-Projected Reflections for Planar Reflectors","keywords":"","body":"Optimized Pixel-Projected Reflections for Planar Reflectors main thoughts limitations 2d simplify scene projection pass basic principle occluded by others reflection pass intermediate buffer holes -> distortion -> filtering -> color bleeding holes distortion filtering algorithm main thoughts reverse the reflection tracing approximate reflective areas of the scene rectangles shader constants limitations 2d simplify scene projection pass basic principle 先相对地面做镜像，再连接相机，判断和平面交点在不在valid area内。 连接相机：对镜像的点做perspective projection, 然后找到该点对应的screen space的depth，反算交点，把reflected color写在交点的buffer里。 occluded by others simply skip outputting reflected color information reflection pass just read the data that was stored for this pixel by the “projection pass”. intermediate buffer single value per pixel filled in the \"projection pass\" closest pixel to be reflected encode a screen-space offset 计算 reflected point 到 reflective point 的距离 --> InterlockedMin 不懂的是为什么要建立4个screen space 的 coordinate systems, 讲道理一个distance就能搞定？？ holes -> distortion -> filtering -> color bleeding holes using value of neighboring pixels distortion filtering filtering with some limitation. decompose colors to hue and luminance and combine those components separately algorithm Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-10-05 11:28:27 "},"GI/ssgi/stochastic_ssr/stochastic_ssr.html":{"url":"GI/ssgi/stochastic_ssr/stochastic_ssr.html","title":"Stochastic Screen Space Ray Tracing","keywords":"","body":"Stochastic Screen Space Ray Tracing tiled-based classification ray classification expensive rays cheap rays blur solutions influences BRDF importance sampling hit point reuse ---> multi-pixel resolve reuse variance reduction resolve temporal filter questions tiled based classification 基于什么方式做？ ray jitter solutions elongation 要怎么resolve才能得到 how to determine mip map level color buffer filtering 要怎么做 elongation 的效果是怎么做的 stochastic 体现在 importance sampling上。 tiled-based classification 先以一个1/8的resolution去做试探性的RT，根据求交的结果来决定ray count. ray classification classify each pixel based on roughness. rt in low resolutionexpensive rays use this one on smooth surfaces, as for mirror-like reflections we would like the intersection points to be as precise as possible. hierarchical ray tracing Monte Carlo importance sampling use importance sampling of the BRDF in order to generate ray directions. Any BRDF can be used here; we happen to worship GGX. generating half-angle vectors, and reflecting them off the microfacet normal. This results in some rays actually pointing below the surface. We can’t use those, so we re-generate them a few times until we get nice ones. importance sample from the Distribution of Visible Normals 怎么重要性采样还要看看源码和多种方式验证下。 ray reuse variance reduction ??? importance sampling bias cheap rays for rough reflections --> linear marcher blur solutions mip maps blur stochastically sampling the directions noisyinfluences roughness normal proximity BRDF importance sampling hit point reuse ---> multi-pixel resolve reuse 基于一种假设：neighbor point 的 visibility 和 target point 是一样的。 color 是用的 自己的 BRDF 算的，但是sampling 除以的 pdf 是用的 target point的。 如果相邻点的材质差别很大的话，会有问题。 variance reduction 造成方差很大的问题是绿色方框里的计算，上面的计算可以减少方差，FG是IBL预烘焙好的。不是特别懂，因为用了精确的FG，所以就更准确了么？？ resolve instead of returning the colors immediately, we barely store the intersection points. Then we have a ‘resolve’ pass, which reuses those intersection points across neighboring pixels. resolve in full resolution Instead of fetching the high frequency color buffer for our reflections, we use appropriately pre-blurred versions of it. resolve four pixel at a time, each pixel has a unique mip level take the reflection distance into account weigh the contributions by each pixel’s BRDF ??? sampling的时候不是已经考虑过权重了，这个要看下实现 temporal filter denoising temporal reprojection calculate the average depth of the reflected objects, and reproject using that. questions tiled based classification 基于什么方式做？ ray jitter solutions elongation 要怎么resolve才能得到 how to determine mip map level color buffer filtering 要怎么做 是否考虑depth filtering weight 怎么算 deferred shading 的 rt 只要 mip map 1elongation 的效果是怎么做的 If you’re using a microfacet BRDF, your analytical lights do this already. ？？ Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-10-05 11:25:41 "},"GI/ssgi/implementation/implementation.html":{"url":"GI/ssgi/implementation/implementation.html","title":"SSGI Implementation Summary","keywords":"","body":"SSGI Implementation Summary pipeline 代码目录 generate hi-z & hi-color mip map tile classification ray marching importance sampling diffuse specular doubts before ray marching diffuse linear ray marching 计算ray的view space下的起点，终点，步长 linear ray marching specular ray marching 计算ray在screen space下的一些数据 hi-z ray marching denoising spatial filtering temporal filtering diffuse specular apply to final future work 性能上 denoising pipeline 代码目录 ssgi_common.hlsl 一些ssgi和ssgi_cs的共用函数，比如对gbuffer的处理等 ssgi.hlsl 非compute shader实现的pass ssgi_cs.hlsl compute shader 实现的pass monte_carlo.hlsl 关于mote carlo importance sampling的一些utility函数实现 ray_cast.hlsl ray marching的实现，包括linear和hi-z ssgi_spatial_filtering.hlsl ssgi denoising的spatial实现 ssgi_temporal_filtering.hlsl ssgi denoising的temporal实现 generate hi-z & hi-color mip map 用一个compute pass 生成 一张1/2 resolution（考虑ray marching的性能）的 depth 和 deferred shading 结果的多 mip level 贴图。 hi-z depth map 每四个像素计算最小的depth存入下一个mip level的对应像素 看了ue的源码里有ClosestHZB和FurthestHZB，一开始不太理解，后来看到别的方案才明白过来，他们的depth图应该有存最小的几个depth，然后在求里面的最大最小(还未验证)。 hi-color map 原理是根据采样点的linear_depth和四个点最小的linear_depth差值来作为权重对color做filtering. tile classification 就是希望通过一些前期的预判减少实际ray marching的无用rays. ray marching 分别对于diffuse 和 specular 进行不同的ray marching算法，ray marching提供最大的rays num和steps的配置。 importance sampling 跟采样相关的实现都放在monte_carlo.hlsl. diffuse sampling 通过rendering equation可以得出，diffuse使用cosine分布的importance sampling是比较合适的 为了使得结果更快的收敛，对一开始的单位圆盘随机采样的结果乘以了一个小于1的bias，使得更多的往normal方向采样。 采样得到的结果就是light direction. rendering cosine sampling最后计算lighting的时候，需要把所有采样到的color求和除以N，然后乘以当前材质的albedo，这个放到最后apply to final 的时候做。specular sampling 分两种情况 roughness roughness >= 0.1 使用的是visible normal GGX importance sampling来采样得到half vector的方法。 http://jcgt.org/published/0007/04/01/ 大致原理是根据normal的tangent space下的view vector方向做投影，然后在投影平面区域做均匀随机采样，再映射回去 rendering 每个采样到的color要乘以fresnel项和G_SMITH_L项再除以N才是最终的rendering result，这个放在ray marching的时候计算。 doubts 这里的采样结果除以的N都是hit==true的点的个数，这个就会造成一个问题就是rays越多越亮，使用总发射的rays个数整体又会太暗，而且感觉也有点不合理，所以这里是有点疑惑的。 before ray marching 关于screen space 和 view space 下的插值换算需要搞搞清楚，要做perspective correct interpolation，不然之后的ray marching 计算交点会有问题。 chrome-extension://cdonnmffkdaoajfknoeeecmchibpmkmg/assets/pdf/web/viewer.html?file=https%3A%2F%2Fwww.comp.nus.edu.sg%2F~lowkl%2Fpublications%2Flowk_persp_interp_techrep.pdf 简单的说就是 屏幕空间的uv插值的scale和view space下的不一样，如图中的s和t 屏幕空间的uv线性插值并不等于view space下的linear depth线性插值，是linear_depth倒数的线性插值 diffuse linear ray marching diffuse为了性能考虑，且diffuse不需要很精确的hit result，所以采用view_space下linear ray marching的方式。 计算ray的view space下的起点，终点，步长 给定一条ray的方向 先根据max_ray_trace_distance, camera的near plane distance 和 far plane distance计算出ray的终点 然后计算ray的终点是否超出camera frustum的范围，如果超出要clip到frustum的边界 注意这里的clip scale需要做perspective-correct interpolation 最后根据steps num算出每一步的步长linear ray marching linear的算法比较简单，就是在view space下每一步走一个固定的步长，通过比较每一步的depth和hi-z采样得到的depth来判断是否打到物体。 和 camera look-at 相同方向的 ray 如果ray的depth比hi-z采样得到的depth大超过一个thickness threshold就算打到。 和 camera look-at 相反方向的 ray 一般刚开始的时候ray的depth都比hi-z depth小一些，所以当ray的depth比hi-z depth大且在没有超过一定threshold的就算打到。 走的越远，mip map level越大 越远会在更大的范围上取color，所以相应的求交的范围也越大。 diffuse ray marching的结果 specular ray marching specular 因为需要更加精确的hit result，所以采用hi-z ray marching的方式。 计算ray在screen space下的一些数据 主要是根据ray的world space下的方向计算起点和一定步长下的一个终点的screen space uv 和 linear depth，然后根据perspective-correct interpolation对ray marching的点进行插值。 hi-z ray marching principle 大致的原理是根据是否hit来不断增大或者缩小hi-z texture的mip level. code 重点解释下是如何实现每次只前进一个pixel(不同mip level的pixel大小不同) 先根据当前mip level计算出resolution是多少 再根据screen space的ray方向将当前点挪到当前pixel的corner上 eg. u 再根据screen space的ray方向计算一个挪动到下一个pixel的offset值 corner加上一个offset，然后除以screen direction取u,v中最小的步长得到下一步应该走到哪里 得到了下一步的uv，再根据perspective-correct interpolation计算下一步的linear depth denoising chrome-extension://cdonnmffkdaoajfknoeeecmchibpmkmg/assets/pdf/web/viewer.html?file=https%3A%2F%2Flink.springer.com%2Fcontent%2Fpdf%2F10.1007%252F978-1-4842-7185-8_49.pdf 参考的是NVIDIA Real-Time Denoisers library (NRD) 里的ReBLUR算法的两步 ： REBLUR_Diffuse_PreBlur.cs.hlsl REBLUR_Diffuse_TemporalAccumulation.cs.hlslspatial filtering 主要作用是将一些outliers弱化。 8个采样点满足每一帧做随机旋转的poisson分布 加权的权重是一系列因素的合集 view space 上的几何权重 是否在屏幕内 screen uv 偏移的guassian权重 normal 对于specular的材质还有roughness(我们的specular暂时没考虑spatial filtering) temporal filtering diffuse 判断上一帧是不是在屏幕内 判断当前帧的物体上一帧有没有被遮挡 之前用过normal做判断发现会在边缘点闪烁，所以改用roughness 实际NV的实现用了别的方式，但是目前roughness效果也还可以 对history采用catmullrom的算法作filtering 根据当前像素temporal累计的帧数进行累加，最多64 其实本质是求平均 specular 目前采用和diffuse一样的算法，但累计的帧数要少一些，diffuse是64帧，specular是16帧 当然对变化比较快的地方，会有一点lag, 但目前的场景感觉还可以。 之后可以考虑用NV的两种方案做下改进。 apply to final diffuse 和 specular的结果叠加到原来deferred shading的结果上 diffuse项要乘一个albedo, 是要把importance sampling的结果求rendering的结果 future work 性能上 color resolve 之前resolve的方案是把多个ray的hit uv做平均，觉得不是合理，所以暂时舍弃。 但是之前有结果显示，resolve对于性能的提升是比较大的，毕竟复用了周围pixel的rays. 之后会考虑把多个ray的hit uv都保存下来，再加上importance sampling等计算看下结果。 compute shader 中间也试过把ray marching的步骤改成compute shader来实现，发现结果并没有很好。 虽然有一点提升，但结果很受thread group size的影响，这个在不同配置的电脑上是不是也会不一样也有待验证。 所以现在基于debug的便利性和考虑所有配置的适配性还是用vertex, pixel shader去实现。 denoising的pass也可以改成compute shader都试一试。 denoising https://github.com/NVIDIAGameWorks/RayTracingDenoiser/tree/master/Source 现在的denoising只是借鉴了NV实现的两步，但是NV REBLUR的方案性能上也是比较费的。 这个之后有时间要把NV REBULR，SVGF包括shadow去噪的方案再好好实现下，之后可以直接用在RT或者其他GI算法的去噪上。 Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-10-05 11:25:14 "},"GI/precompute/resource.html":{"url":"GI/precompute/resource.html","title":"Precomputed Based GI","keywords":"","body":"Resources PRT(precomputed radiance transfer) Ravi Precomputation-Based Rendering 顶牛Ravi大佬介绍precompution的课件。 sig02, Precomputed Radiance Transfer for Real-Time Rendering in Dynamic, Low-Frequency Lighting Environments lightmaps Frosbite18, path-traced SH lightmaps Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-14 15:28:44 "},"GI/voxel_based/resource.html":{"url":"GI/voxel_based/resource.html","title":"Voxel Based GI","keywords":"","body":"Resources paper Crassin 2011 Interactive Indirect Illumination Using Voxel Cone Tracing voxel数据结构基于sparse octree McLaren 2015 The tomorrow children: lighting and mining with voxels voxel数据存储在多级3D texture mipmap中，渲染的时候基于texture cascade的思路去采样。 implementation https://wickedengine.net/2017/08/30/voxel-based-global-illumination/ https://github.com/compix/VoxelConeTracingGI Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-10-04 17:33:43 "},"GI/distance_field/resource.html":{"url":"GI/distance_field/resource.html","title":"Distance Field","keywords":"","body":"Resources UE4 distance field doc Youtube, Understanding the SDF Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-02-04 15:45:45 "},"GI/lumen/resource.html":{"url":"GI/lumen/resource.html","title":"Lumen","keywords":"","body":"Resources course UDC 虚幻引擎5渲染特性解析 Lumen | Epic Games 王祢 Final Gather Radiance Caching for Real-Time Global Illumination source code 游戏引擎随笔 0x29：UE5 Lumen 源码解析 Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-10-04 17:35:50 "},"pbr/resource.html":{"url":"pbr/resource.html","title":"PBR","keywords":"","body":"Resources Physically based shading references, at the end of 2019 一份比较详细的19年及其以前的PBR资料整理 Courses SIGGRAPH Courses: Physically Based Shading in Theory and Practice Books Real-Time Rendering Physically Based Rendering Engine PBR Realization Disney 12, Physically Based Shading at Disney. Physically Based Shading in Film and Game Production, ACM SIGGRAPH 2012 Courses Moving Frostbite to PBR Filament UE4 Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-05-14 06:49:05 "},"pbr/rtr_pbr/rtr_pbr.html":{"url":"pbr/rtr_pbr/rtr_pbr.html","title":"Real-Time PBR Summary","keywords":"","body":"Real-Time PBR Summary Physics of Light physical optics particles media surfaces subsurface scattering The Camera pinhole physically based camera The BRDF definition models of BRDF Local Illumination Fresnel Reflectance definition assumption reflection vs. refraction External Reflection physics mathematical model Typical Fresnel Reflectance Values dielectrics metals semiconductors fresnel reﬂectance values in water parameterizing fresnel values Internal Reflection Microgeometry microgeometry on specular reflectance microgeometry on subsurface reflectance Microfacet Theory definition modeling NDF masking and shadowing function BRDF Models for Surface Reflection half vector specular BRDF NDF isotropic NDF anisotropic NDF multiple-bounce surface reﬂection BRDF Models for Subsurface Scattering subsurface albedo scale of subsurface scattering and roughness smooth-surface subsurface models rough-surface subsurface models BRDF Models for Cloth Empirical Cloth Models Uncharted 2 diffuse BRDF Uncharted 4 diffuse term Disney diffuse sheen term Microfacet Cloth Models Game The Order: 1886 Imageworks Micro-Cylinder Cloth Models Wave Optics BRDF Models Diffraction Models Models for Thin-Film Interface Layered Materials clear coat layered material models Blending and Filtering Materials Material Blending Material Filtering Filtering Normals and Normal Distributions Physics of Light physical optics Light waves carry energy --> irradiance (d phi / d A) proportional to the square of the amplitudes constructive interference vs. destructive interference particles isolated molecules the scattered waves are incoherent and their energy adds linearly multi-molecule clusters the scattered light waves in each cluster are in phase and interfere constructively. This causes the scattered wave energy to add up quadratically media homogeneous media non-homogeneous media scattering and absorption surfaces An object surface is a two-dimensional interface separating volumes with diﬀerent index of refraction(IOR) values. transmitted wave and reﬂected wave have the same frequency as the incident wave the phase velocity—the speed the wave travels through the medium—changes proportionally to the relative index of refraction (n 1 /n 2 ). Since the frequency is ﬁxed, the wavelength also changes proportionally to (n 1/n 2) Snell's law subsurface scattering local vs. global subsurface scattering specular term models surface reﬂection diffuse term models local subsurface scattering The Camera pinhole a zero-size mathematical point and no lens restricts each point on the sensor surface to collect a single ray of light physically based camera including a lens allows for the use of a larger aperture have a limited depth of ﬁeld The BRDF definition bidirectional reﬂectance distribution function (BRDF) f(l, v) reflectance equation two constraints for BRDF Helmholtz reciprocity conservation of energy the outgoing energy cannot be greater than the incoming energy models of BRDF Lambertian BRDF is a constant others Local Illumination 为什么会多个pi，感觉不合理啊，跟c_light的定义有关 directional light punctual light Fresnel Reflectance definition The interaction of light with a planar interface between two substances follows the Fresnel equations developed by Augustin-Jean Fresnel. assumption The surface is assumed to not have any irregularities between 1 light wavelength and 100 wavelengths in size. reflection vs. refraction reflection direction Fresnel reflectance F The amount of light reﬂected (as a fraction of incoming light) is described by the Fresnel reﬂectance F, which depends on the incoming angle. refraction depends on the refractive indexes(n_1, n_2) of substances on the two sides of the surface External Reflection physics External reﬂection is the case where n1 incoming angle = 0° ---> F = F0 incoming angle = 90° ---> F = 1 为什么要根据sin角度作为x轴，因为透视缩短 mathematical model Schlick’s pros simple calculation cons artifacts near grazing angle Typical Fresnel Reflectance Values dielectrics For unknown dielectrics, 0.04 is a reasonable default value, not too far oﬀ from most common materials. metals Recall that metals immediately absorb any transmitted light, so they do not exhibit any subsurface scattering or transparency. All the visible color of a metal comes from F0 . semiconductors fresnel reﬂectance values in water in air ---> n ≈ 1 in water ---> n ≈ 1.33 parameterizing fresnel values using metallic to represent specular color F0 or the diffuse color in one texture no materials have values of F0 lower than 0.02, values of F0 below 0.02 are used to “turn oﬀ” Fresnel edge brightening Internal Reflection Internal reﬂection happens when n1 > n2. eg. traveling in the interior of a transparent object and encounters the object’s surface total internal reﬂection when outcoming angle is larger than 90° Microgeometry microgeometry on specular reflectance reflectance shadowing and masking interreflection microgeometry on subsurface reflectance retroreflection retroreﬂection tends to give rough surfaces a ﬂat appearance Microfacet Theory definition The theory is based on the modeling of microgeometry as a collection of microfacets. Each of these tiny facets is ﬂat, with a single microfacet normal m diffuse/specular/diffraction micro-BRDF modeling NDF statistical distribution of the microfacet normals m masking and shadowing function G1(m, v), the fraction of microfacets with normal m that are visible along the view vector v. Heitz, Eric, “Understanding the Masking-Shadowing Function in Microfacet-Based BRDFs\" Smith masking function overall macrosurface BRDF joint masking-shadowing function G2(l, v, m) uncorrelated nonphysically assumption which cause over-darkening relative azimuth angle between v and l height correlation height and direction correlation BRDF Models for Surface Reflection The specular BRDF terms used in physically based rendering are derived from microfacet theory. half vector specular BRDF Walter, Bruce, Stephen R. Marschner, Hongsong Li, and Kenneth E. Torrance, “Microfacet Models for Refraction through Rough Surfaces,” Rendering Techniques 2007, Eurographics Association, pp. 195–206, June 2007. NDF isotropic NDF Beckmann NDF alpha_b controls the surface roughness, it is proportional to the root mean square (RMS) slope of the microgeometry surface, so α b = 0 represents a perfectly smooth surface. deriving the Smith G2 function Blinn-Phong NDF GGX NDF comparison GGX has narrower peaks than Beckmann, as well as longer “tails” surrounding those peaks, which create the appearance of a haze or glow around the core of the highlight. other NDFs generalized Trowbridge-Reitz (GTR) NDF Student’s t-distribution (STD) exponential power distribution (EPD) adding a second lobe ---> a mix of two GGX NDFs anisotropic NDF The microfacet normal m needs to be transformed into the local frame or tangent space deﬁned by the normal, tangent, and bitangent vectors, respectively, n, t, and b. generalize from an isotropic NDF parameterization multiple-bounce surface reﬂection The microfacet BRDF framework does not account for light that is reﬂected (“bounced”) from the microsurface multiple times. This simpliﬁcation causes some energy loss and over-darkening, especially for rough metals Kulla, Christopher, and Alejandro Conty, “Revisiting Physically Based Shading at Imageworks,” SIGGRAPH Physically Based Shading in Theory and Practice course, Aug. 2017. BRDF Models for Subsurface Scattering BRDF models for local subsurface scattering, or diﬀuse surface response, in opaque dielectrics. subsurface albedo the ratio between the energy of the light that escapes a surface compared to the energy of the light entering into the interior of the material. can depend on wavelength, light reﬂecting diﬀusely will be colored from absorption by the pigment particles since dielectrics transmit most incoming light rather than reﬂecting it at the surface, the subsurface albedo is usually brighter and thus more visually important than the specular color F0 subsurface albedo can be thought of as the result of a “race” between absorption and scattering scale of subsurface scattering and roughness The correct deciding factor for which type of BRDF model to use relates to the relative size of the surface irregularities and the subsurface scattering distances. top left --> diffuse micro-BRDF top right --> smooth-surface diffuse model bottom --> rough-surface diffuse model smooth-surface subsurface models These are appropriate for modeling materials where the surface irregularities are smaller than the subsurface scattering distances. Diﬀuse shading is not directly aﬀected by surface roughness. Lambertian consider the Fresnel effect Shirley, with perfect Fresnel mirror specular term Kelemen and Szirmay-Kalos, with any specular term rough-surface subsurface models Disney Oren-Nayar a Lambertian micro-BRDF a spherical Gaussian NDF Torrance-Sparrow “V-cavity” masking-shadowing function Hammon consider interreflections with a two-bounce simulation surface irregularities are larger than scattering distances BRDF Models for Cloth Empirical Cloth Models Uncharted 2 diffuse BRDF Uncharted 4 diffuse term Disney diffuse sheen term Microfacet Cloth Models Each of the cloth models we have seen so far are limited to speciﬁc types of fabric. Game The Order: 1886 Velvet BRDF Imageworks Micro-Cylinder Cloth Models The micro-cylinder models used for cloth are quite similar to those used for hair. Kajiya and Kay Model DreamWorks relatively simple and artist-controllable microcylinder model for fabric “Physically Based Shading at DreamWorks Animation,” SIGGRAPH Physically Based Shading in Theory and Practice course, Aug. 2017 using actual hair BSDF models Wave Optics BRDF Models Geometrical optics, which treats light as propagating in rays rather than waves, is based on the assumption that any surface irregularities are either smaller than a wavelength or larger than about 100 wavelengths. Surface with nanogeometry need using wave nature of light and wave optics to model some effects. Diffraction Models Huygens-Fresnel principle every point on a wavefront (the set of points that have the same wave phase) can be treated as the source of a new spherical wave. real-world phenomena CD and DVD optical disks and certain insects researches Holzschuch, Nicolas, and Romain Pacanowski, “Identifying Diﬀraction Eﬀects in Measured Reﬂectances,” Eurographics Workshop on Material Appearance Modeling, June 2015. Toisoul, Antoine, and Abhijeet Ghosh, “Real-Time Rendering of Realistic Surface Diﬀraction with Low Rank Factorisation,” European Conference on Visual Media Production (CVMP), Dec. 2017. Models for Thin-Film Interface definition Thin-ﬁlm interference is a wave optics phenomenon that occurs when light paths reﬂecting from the top and bottom of a thin dielectric layer interfere with each other. The reason that the ﬁlm needs to be thin for this eﬀect to occur is related to the concept of coherence length. This length is the maximum distance by which a copy of a light wave can be displaced and still interfere coherently with the original wave. This length is inversely proportional to the bandwidth of the light, which is the range of wavelengths over which its spectral power distribution (SPD) extends. real-world phenomena soap bubbles and oil stains researches Drobot, Michal, “Practical Multilayered Materials in Call of Duty Inﬁnite Warfare,” SIGGRAPH Physically Based Shading in Theory and Practice course, Aug. 2017 Belcour, Laurent, and Pascal Barla, “A Practical Extension to Microfacet Theory for the Modeling of Varying Iridescence,” ACM Transactions on Graphics (SIGGRAPH 2017) Layered Materials clear coat realization Disney UE Pixar Dreamworks Imageworks properties The most notable visual result of a clear-coat layer is the double reﬂection resulting from light reﬂecting oﬀ both the clear-coat and the underlying substrate. tinted clear-coat caused by absorption depends on the length of the path length that light travels which is view-dependent diﬀerent layers could have diﬀerent surface normals layered material models Drobot, Michal, “Practical Multilayered Materials in Call of Duty Inﬁnite Warfare,” SIGGRAPH Physically Based Shading in Theory and Practice course, Aug. 2017. Blending and Filtering Materials Material Blending Material blending is the process of combining the properties, i.e., the BRDF parameters, of multiple materials. Material Filtering Filtering Normals and Normal Distributions normal filtering solutions modify roughness according to unnormalized average normal length mapping the covariance matrix of the normal distribution geometry curvature estimation sparkly appearance render sparkling snow in the game Disney Inﬁnity 3.0 Bowles, Huw, and Beibei Wang, “Sparkly but not too Sparkly! A Stable and Robust Procedural Sparkle Eﬀect,” SIGGRAPH Advances in Real-Time Rendering in Games course, Aug. 2015. Zirr, Tobias, and Anton Kaplanyan, “Real-Time Rendering of Procedural Multiscale Materials,” Symposium on Interactive 3D Graphics and Games, Feb. 2016. Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-05-27 11:29:50 "},"pbr/material/resource.html":{"url":"pbr/material/resource.html","title":"Material","keywords":"","body":"Resources Books Real-Time Rendering Chapter 9 BSDF models BRDF 重要的papers Microfacet Models for Refraction through Rough Surfaces, 2007 Eric Heitz, Understanding the Masking-Shadowing Function in Microfacet-Based BRDFs, 2014 这篇paper真的不错，把BRDF, NDF, shadowing-masking的原理和关系讲的很清楚，想要真的弄懂那些公式怎么来的，这个必看。 有一些细节的定义和推导可以再结合第一篇paper看下。 毛星云，基于物理的渲染（PBR）白皮书 Uber BSDF Disney BSDF 2012 Siggraph course, Physically Based Shading at Disney (Brent Burley) 2015 Siggraph course, Extending the Disney BRDF to a BSDF with Integrated Subsurface Scattering (Brent Burley) Autodesk Standard Surface Unreal Engine 4 Physically-based Material Substance’s Physically-Based Shaders PBR guide Hair Skin Cloth Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-05-13 21:18:03 "},"pbr/material/reflection_models/reflection_models.html":{"url":"pbr/material/reflection_models/reflection_models.html","title":"Reflection Models","keywords":"","body":"Reflection Models Reflection Models reflection models categories geometric settings specular reflection and transmission Fresnel Reflectance --- amount of reflection Index of refraction 定义 two dielectric media a conductor and a dielectric medium semiconductors (not included) specular reflection specular transmission Lambertian Reflection Microfacet Models Oren–Nayar Diffuse Reflection main thoughts model Normal Distribution Function Beckmann and Spizzichino Model Trowbridge and Reitz Model comparison Masking and Shadowing Smith masking-shadowing function G_1(w, w_h) Beckmann–Spizzichino distribution Trowbridge–Reitz distribution both direction geometry function G(w_o, w_i) independently for w_o, w_i dependently The Torrance–Sparrow Model basic thoughts Torrance–Sparrow BRDF Torrance-Sparrow BRTF Fresnel Incidence Effects basic principle Ashikhmin and Shirley model glossy specular term diffuse term FourierBSDF objective represents isotropic BSDFs specified BSDF value Catmull–Rom spline interpolation reflection models categories diffuse glossy specular perfect specular retro-reflective eg. velvet 天鹅绒geometric settings specular reflection and transmission 镜面反射 遵从 Snell’s law的透射 理论上，the index of refraction varies with the wavelength of light (eg. 色散), 但是为了简化，忽略波长的因素 Fresnel Reflectance --- amount of reflection Index of refraction 定义 the ratio of the speed of light in a vacuum to the speed of light in the medium. two dielectric media index of refraction complex index of refraction --- absorption a conductor and a dielectric medium semiconductors (not included) specular reflection specular transmission Fresnel现象：transmission is stronger at near-perpendicular angles Lambertian Reflection models a perfect diffuse surface that scatters incident illumination equally in all directions const Spectrum R gives the fraction of incident light that is scattered BRDF f = R / pi (pi 是 cos(theta)在半球上的积分) Microfacet Models rough surfaces can be modeled as a collection of small microfacets a representation of the distribution of facets a BRDF that describes how light scatters from individual microfacets Oren–Nayar Diffuse Reflection main thoughts real-world objects do not exhibit perfect Lambertian reflection describes rough surfaces by V-shaped microfacets described by a spherical Gaussian distribution with a single parameter theta, the standard deviation of the microfacet orientation angle. model Normal Distribution Function NDF必须归一化 Beckmann and Spizzichino Model isotropic anisotropic Trowbridge and Reitz Model comparison Trowbridge–Reitz has higher tails—it falls off to zero more slowly for directions far from the surface normal. This characteristic matches the properties of many real-world surfaces well. Masking and Shadowing Smith masking-shadowing function G_1(w, w_h) 必须满足归一化条件 basic thoughts forward-facing facets 的投影面积 减去 backward-facing facets的投影面积 auxiliary function Beckmann–Spizzichino distribution assume that there is no correlation between the heights of nearby points on the microsurface function a rational polynomial approximation Trowbridge–Reitz distribution both direction geometry function G(w_o, w_i) independently for w_o, w_i dependently microfacet visibility is more likely the higher up a given point on a microfacet is The Torrance–Sparrow Model basic thoughts modeled surfaces as collections of perfectly smooth mirrored microfacets only consider the half vector. Torrance–Sparrow BRDF perfect specular reflection Torrance-Sparrow BRTF perfect specular transmission Fresnel Incidence Effects basic principle 这个关心的是上一层材质的Fresnel reflection是如何影响下一层材质的入射光照的。 Fresnel reflection reduces the amount of light that reaches the bottom level of layered objects. Ashikhmin and Shirley model models a diffuse underlying surface with a glossy specular surface above it. glossy specular term diffuse term R_d diffuse surface reflectance, R_s specular surface reflectance FourierBSDF objective 一些复杂的材质很难用一个通用BXDF公式去描述。 一种思路是存a large 3D or 4D lookup table，但是这样数据量会太大。 想要寻求的是a more compact representation that still represents the BSDF accurately， FourierBSDF就是这样的一个解决方案。 核心思想是sums of scaled cosine terms using the Fourier basis. represents isotropic BSDFs 因为isotropic，所以有对称性，所以没有sin项。 specified BSDF value 找到临近的离散值，做一定的插值得到Fourier系数，然后计算BSDF值。 Catmull–Rom spline interpolation objective 对于一个function f, 对每一段区间[x_i, x_i+1]希望用a cubic polynomial来拟合这个函数： 使得这个多项式满足 calculation 因为原函数未知，导数不好求所以用近似的方法 Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-03-02 16:42:21 "},"pbr/material/brdf/brdf.html":{"url":"pbr/material/brdf/brdf.html","title":"Deep in Microfacet BRDF","keywords":"","body":"Deep in Microfacet BRDF Reference Some Microfacet Theory Measuring Radiance on a Surface Microfacet Statistics The Distribution of Normals Microfacet Projections A Constraint on the Masking Function Microfacet-Based BRDFs Distribution of Visible Normals Construction of the BRDF Construction of The BRDF with Specular Microfacets Construction of The BRDF with Diffuse Microfacets The BRDF Normalization Test The White Furnace Test Good Summary Normal Distribution Functions How is the NDF really defined Isotropic NDF Blinn-Phong Beckmann GGX(Trowbridge-Reitz) Generalized-Trowbridge-Reitz（GTR） Masking Functions The Smith Microsurface Profile normal/masking independence derive the Smith masking function properties The V-Cavity Microsurface Profile major principle NDF masking function properties Non-Physically Based Masking Functions what is \"physically based\" The Implicit Masking Function The Schlick-Smith Masking Function The Kelemen Masking Function Summary Stretch Invariance of the Masking Function Masking Probability Invariance The Distribution of Slopes Isotropic Shape-Invariant Distributions of Slopes Shape Invariance Beckmann Distribution GGX Distribution Shape-Variant Distributions Anisotropic Shape-Invariant Distributions of Slopes Shape Invariance Derivation of the Masking Function Anisotropic Beckmann Distribution Anisotropic GGX Distribution More Generalization Arbitrary Shape-Invariant Distributions Non Axis-Aligned Stretching Vertical Shearing and Non-Centered Distributions The Smith Joint Masking-Shadowing Function Separable Masking and Shadowing Height-Correlated Masking and Shadowing Direction-Correlated Masking and Shadowing Height-Direction-Correlated Masking and Shadowing Reference Microfacet Models for Refraction through Rough Surfaces, 2007 Eric Heitz, Understanding the Masking-Shadowing Function in Microfacet-Based BRDFs, 2014 这篇paper真的不错，把BRDF, NDF, shadowing-masking的原理和关系讲的很清楚。 Some Microfacet Theory Measuring Radiance on a Surface Microfacet Statistics Microfacet theory is a statistical model of the scattering properties of the micro-surface. The Distribution of Normals D is actually the distribution of normals per square meter of the geometric surface and this is why it is measured in m2/sr and not in 1/sr Microfacet Projections A Constraint on the Masking Function constraint 1 : projection area constraint 2 : microsurface profile the distribution of normals is like a histogram, describing only the proportion of each normal on the microsurface. microsurface provide information of how microsurfaces are organized 即给定microsurface profile, 就可以推出masking function Microfacet-Based BRDFs Distribution of Visible Normals 注意， D的单位是m^2/sr, D_wo的单位是1/sr, 归一化指的是投影面积上的归一化 Construction of the BRDF micro-BRDF macro-BRDF introducing masking-shadowing function w_g dot w_o 是normalize the integral by the projected area of the geometric surface on outgoing direction引入的 w_g dot w_i 是入射光在投影面积上的分量引入的 Construction of The BRDF with Specular Microfacets jacobian 项怎么来的 是把outgoing方向的变量替换成half vector变量产生的jacobian项 hr 替换成 i+o 就能得到上面的式子 Construction of The BRDF with Diffuse Microfacets The BRDF Normalization Test The White Furnace Test BSDF BRDF+BTDF White Furnace Test assume no absorption, no transmitted rays and all rays are reflected without energy loss https://github.com/knarkowicz/FurnaceTest 白炉测试的实现 The Weak White Furnace Test without Fresnel and shadowing Good Summary Normal Distribution Functions How is the NDF really defined https://www.reedbeta.com/blog/hows-the-ndf-really-defined/ the density of micro-area over the joint domain of macro-area and solid angle Isotropic NDF https://zhuanlan.zhihu.com/p/69380665 Blinn-Phong not shape-invariant Beckmann shape-invariant GGX(Trowbridge-Reitz) Generalized-Trowbridge-Reitz（GTR） Masking Functions The Smith Microsurface Profile normal/masking independence The Smith microsurface profile assumes that the microsurface is not autocorrelated. derive the Smith masking function 把normal space 转换到slope space进行计算 properties uncorrelated assumption can cause artifacts The V-Cavity Microsurface Profile major principle Each microsurface is composed of two normals ωm = (xm,ym,zm) and ωm′ = (−xm,−ym,zm) and the contribution of each microsurface is weighted by D(ωm) in the final BRDF. NDF 考虑到归一化 masking function V-cavity masking function properties For a single microsurface, highly visible normals would occupy more projected area than less visible normals and thus have a higher contribution. There is no view dependence in the weighting (except that backfacing normals are discarded). This is why the V-cavity model poorly incorporates the effect of visibility and ends up simulating something close to a normal map. no such effect of V-cavity model that BRDF distribution shifted toward the outgoing direction as roughness increase Non-Physically Based Masking Functions what is \"physically based\" ensure conservation of the projected are satisfy the Weak White Furnace Test The Implicit Masking Function does not satisfy the conservation of the projected area The Schlick-Smith Masking Function The Kelemen Masking Function Summary The real reason to choose it is that Smith’s formula is the exact masking function under the assumption of the chosen microsurface profile (i.e. normal/masking independence). Stretch Invariance of the Masking Function Investigate the invariance property of the masking function and of the distribution of slopes when the configuration is stretched. Masking Probability Invariance After stretching, occluded rays are still occluded and unoccluded rays are still unoccluded --- the masking probability is invariant to configuration stretching when all of the slopes involved in the configuration are scaled at the same time. The Distribution of Slopes the distribution of heights of the microsurface is often denoted P1(h) distribution of slopes of the microsurface 注： tan的倒数是1/ (cos^2)Isotropic Shape-Invariant Distributions of Slopes Shape Invariance changing roughness is equivalent to stretching the distribution without changing its shape the masking function depends Beckmann Distribution GGX Distribution Shape-Variant Distributions Phong distribution Anisotropic Shape-Invariant Distributions of Slopes Shape Invariance Derivation of the Masking Function any configuration with an anisotropic shape-invariant distribution can be trans- formed back to a configuration with an isotropic distribution Anisotropic Beckmann Distribution Anisotropic GGX Distribution More Generalization Arbitrary Shape-Invariant Distributions An important property of shape-invariant distributions is that all of the information required for the masking function is contained in the same 1D function Λ, for any roughness or anisotropy. Non Axis-Aligned Stretching Vertical Shearing and Non-Centered Distributions The masking function is also invariant under vertical shearing, because the roughness and the normalization factor are invariant under shearing—which alters all the slopes, and hence the normal vectors—these might also be invariant under a rotation of the normals. The Smith Joint Masking-Shadowing Function Separable Masking and Shadowing does not model correlations between masking and shadowing, and therefore always overestimates shadowing since some correlation always exists Height-Correlated Masking and Shadowing the more a microfacet is elevated within the microsurface, the more the probabilities of being visible for the outgoing direction (unmasked) and for the incident direction (unshadowed) increase at the same time. This form is accurate when the outgoing and incident directions are far away from each other, but overestimates shadowing when the directions are close. derivation suppose that there is no directional correlation for masking from directions ωo and ωi, then the probability that a point at height h is visible from both directions is just the product of the probabilities Direction-Correlated Masking and Shadowing Masking and shadowing are also strongly correlated when the outgoing and incident directions are close to one another. Height-Direction-Correlated Masking and Shadowing Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-05-13 21:53:25 "},"pbr/lighting/resource.html":{"url":"pbr/lighting/resource.html","title":"Lighting","keywords":"","body":"Resources light units light sources Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-14 09:25:34 "},"pbr/solutions/resource.html":{"url":"pbr/solutions/resource.html","title":"Solutions","keywords":"","body":"Resources Disney Frosbite UE Filament Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-08-01 10:21:45 "},"pbr/lighting/filament_base_lighting/filament_base_lighting.html":{"url":"pbr/lighting/filament_base_lighting/filament_base_lighting.html","title":"Filament Basic Physical Lighting","keywords":"","body":"Filament Basic Physical Lighting light units (统一度量衡) luminous intensity 和 illuminance 的转换关系 direct Lighting directional light diffuse almost correct, but specular has artifacts E⊥ is the illuminance of the light source for a surface perpendicular to said light source punctual light point light 球面积分的式子应该少了一项sin(theta)项 spot light 但是为了方便artist调节参数，需要把outer angle和perceived illuminance解耦，近似成 但是也仅限于a matte, diffuse mask that absorbs light的材质才近似物理正确。 最终，spot light 的 render equation有如下形式： attenuation function 但其实point light和spot light并不遵循inverse square law attenuation. Photometric lights 如何给artist更大的自由去控制the distribution of light within the space. Photometric lights use a photometric profile to describe their luminous intensity distribution. IES (Illuminating Engineering Society) EULUMDAT (European Lumen Data format) 比punctual light多一项各个方向采样的intensity IES profile生成pass使用的a photometric profile as a texture的两种方式： - Photometric profile as a mask - Photometric profile float multiplier; // Photometric profile used as a mask if (photometricLight.isMasked()) { // The desired intensity is set by the artist // The integrated intensity comes from a Monte-Carlo // integration over the unit sphere around the luminaire multiplier = photometricLight.getDesiredIntensity() / photometricLight.getIntegratedIntensity(); } else { // Multiplier provided for convenience, set to 1.0 by default multiplier = photometricLight.getMultiplier(); } // The max intensity in cd comes from the IES profile float lightIntensity = photometricLight.getMaxIntensity() * multiplier; Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-14 11:08:28 "},"light/resource.html":{"url":"light/resource.html","title":"Light","keywords":"","body":"Resources punctual light Real-TIme Rendering, chapter 5.2, Light Sources area light Unity, Real-Time Polygonal-Light Shading with Linearly Transformed Cosine Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-06-14 11:55:13 "},"light/punctual/punctual.html":{"url":"light/punctual/punctual.html","title":"Punctual Light","keywords":"","body":"Punctual Light Punctual Light 守时的光源？？ light direction Point/Omni Light attenuation singularity problem self-defined attenuation function large distances calculation Spot Light Others 守时的光源？？ 最开始看到punctual light的时候查了下字典，punctual是守时的精确的，再带进去实在是很费解。然后看了RTR这本书的对应章节才明白： We use the term “punctual,” from the Latin punctus meaning “point,” for the class consisting of all sources of illumination that originate from a single, local position. light direction Point/Omni Light attenuation 其实主要是想看看这个衰减函数的，因为上周在分享一篇关于点光衰减函数的时候会发现在到光源距离r无限小的时候，光强会趋于无穷大，就会有点费解，那点光的intensity的定义究竟是什么，然后在书里找到了答案： 点光的衰减函数就是距离平方的倒数，通常我们定义的点光的intensity实际是在某个给定距离下的intensity. 这样一说就觉得比较合理了。 singularity problem 距离平方的倒数的衰减函数就会面临一个除0的问题，以下会有一些解决办法： 分母加上一个很小的数 UE 的DeferredLightingCommon.ush里实现是取的1 cm. 距离做截断 CryEngine and Frostbite 是这么做的，it has a physical interpretation: the radius of the physical object emitting the light, 这里考虑了光源的物理半径。 siggraph 2020 talk http://www.cemyuksel.com/research/pointlightattenuation/ 作者把点光近似为一个spherical disk light, 把距离的attenuation转换成立体角的大小。 在距离比较小的时候对inverse squared有更好的近似。 self-defined attenuation function 对于有些场景，拟合inverse-square curve没有那么必要，就可以根据需要定义自己的衰减函数： large distances calculation 距离比较远了之后，点光衰减的很多几乎接近于0，从性能上考虑，这部分计算性价比就不高了。 和一个 windowing function 相乘 UE 和 Frostbite 都用的窗口函数是（unreal 里的 attenuation radius就是r_max）： Spot Light spot light相比点光还多了一个方向上的衰减函数。 Frosbite 中使用的函数 Others IES profiles falloﬀ functions for distance along the x, y, and z world axes vary light intensity over time Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-06-14 11:56:40 "},"color/resource.html":{"url":"color/resource.html","title":"Color","keywords":"","body":"Resources Real-Time Rendering Chapter8 Light and Color 一个很好的介绍Color相关的系列博客 Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-05-05 10:55:39 "},"color/light_color/light_color.html":{"url":"color/light_color/light_color.html","title":"Real-Time Light and Color Summary","keywords":"","body":"Real-Time Light and Color Light Quantities Radiometry(辐射度量学) Photometry Colorimetry(色度学) Rendering with RGB colors Display Encoding linear vs. nonlinear EOTF vs. OETF gamma correction transformation problem with neglecting gamma correction Scene to Screen High Dynamic Range Display Encoding Tone Mapping Tone Reproduction Transform Exposure Color Grading Light Quantities Radiometry(辐射度量学) Radiometry deals with the measurement of electromagnetic radiation. Radiant ﬂux is the ﬂow of radiant energy over time—power—measured in watts (W). Radiance, L(lambda, x, d), is a measure of electromagnetic radiation in a single ray An important property of radiance is that it is not aﬀected by distance, ignoring atmospheric eﬀects such as fog. SPD Photometry Photometry, is like radiometry, except that it weights everything by the sensitivity of the human eye. The conversion curve and the units of measurement are the only diﬀerence between the theory of photometry and the theory of radiometry. CIE photometric curve units Luminance is often used to describe the brightness of ﬂat surfaces. Colorimetry(色度学) Colorimetry deals with the relationship between spectral power distributions(SPD) and the perception of color. human biology For color perception, the eye works by having three diﬀerent types of cone receptors in the retina, with each type of receptor responding diﬀerently to various wavelengths. color matching function For an arbitrary spectral distribution, the color-matching functions can be multiplied by the distribution and the area under each resulting curve (i.e., the integral) gives the relative amounts to set the colored lights to match the perceived color produced by the spectrum ---diﬀerent spectral distributions can resolve to the same three weights --- metamer(条件等色) 任意服从一个SPD的光，都可以用积分计算出以三个颜色为基本组成的color-matching functions的权重组合。 mathematical abstraction color matching function transformation between a SPD These X, Y , and Z tristimulus values are weights that deﬁne a color in CIE XYZ space. CIE 1931 chromaticity diagram 对X, Y, Z做归一化，简化成2维to describe just the chromaticity, keeping luminance constant other color spaces linear sRGB color space sRGB to XYZ Y means luminance Rendering with RGB colors Strictly speaking, RGB values represent perceptual rather than physical quantities. Using them for physically based rendering is technically a category error. physically correct spectral reﬂectance curve SPD of incident light * spectral reflection curve = SPD of reflected light in predictive rendering, these subtle errors can be important for the majority of rendering systems, RGB rendering works surprisingly well Display Encoding linear vs. nonlinear linear When we calculate the eﬀect of lighting, texturing, or other operations, the values used are assumed to be linear. Informally, this means that addition and multiplication work as expected. nonlinear To avoid a variety of visual artifacts, display buﬀers and textures use nonlinear encodings that we must take into account. EOTF vs. OETF electrical optical transfer function (EOTF) / display transfer function describes the relationship between the digital values in the display buﬀer and the radiance levels emitted from the display optical electric transfer function (OETF) the opposite of EOTF gamma correction 因为display equipment的buffer值和真正展示的radiance是非线性的关系，但是我们又希望whatever value we compute will emit a corresponding radiance level(即我们计算得到的值和emit的值是线性的)，那么我们就要cancel out the display transfer function ---- 这个过程叫gamma 校正 transformation linear to sRGB sRGB to linear problem with neglecting gamma correction lower linear values will appear too dim on the screen shading computations that are correct for physically linear radiance values are performed on nonlinear values aﬀects the quality of antialiased edges Scene to Screen High Dynamic Range Display Encoding HDR displays use the Rec. 2020 and Rec. 2100 standards. color gamut nonlinear display encodings Rec. 2100 deﬁnes two nonlinear display encodings: perceptual quantizer (PQ) [1213] and hybrid log-gamma (HLG). The HLG encoding is not used much in rendering situations, so we will focus here on PQ, which deﬁnes a peak luminance value of 10, 000 cd/m^2 transfer to an HDR display RGB value: the rendering color space --> Rec.2020 color space apply the PQ encoding Tone Mapping Tone mapping or tone reproduction is the process of converting scene radiance values to display radiance values. The process of scaling by exposure and then applying a tone reproduction transform is a type of global tone mapping. Tone Reproduction Transform Tone reproduction transforms are often expressed as one-dimensional curves mapping scene-referred input values to display-referred output values. applied independently to R, G, and B values may cause shifts in saturation and hue applied to luminance the resulting display-referred color may be out of the display’s RGB gamut, in which case it will need to be mapped back in Exposure Relies on analyzing the scene-referred luminance values. To avoid introducing stalls, this analysis is typically done by sampling the previous frame. the log-average scene luminance a histogram of luminance values Color Grading Color grading is typically performed by interactively manipulating the colors in an example scene image, until the desired creative “look” is achieved. a three-dimensional color lookup table (LUT) grading scene-referred data scene-referred data must be remapped to the range [0, 1] before grading Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-05-05 14:57:17 "},"shadow/resource.html":{"url":"shadow/resource.html","title":"Shadow","keywords":"","body":"Resources theory real-time rendering chapter 7 games202 lesson 3-5 solutions Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2023-06-12 11:51:49 "},"shadow/shadow_summary/shadow_summary.html":{"url":"shadow/shadow_summary/shadow_summary.html","title":"Real-Time Shadow Summary","keywords":"","body":"real-time shadow summary 补点常识吧 basic things soft shadow The math behind shadow mapping state of art projection shadow projective texture mapping shadow volume shadow maps basic principle shadow map problems and solutions 软阴影 PCF(Percentage-Closer Filtering) PCSS(Percentage-Closer Soft Shadows) filtered shadow map VSM(Variance Shadow Map) CSM (Convolution Shadow Mapping) & ESM(Exponential Shadow Map) Moment Shadow Mapping SDF(Signed Distance Field) volumetric shadow technique transparency depth map deep shadow maps opacity shadow maps，adaptive volumetric shadow maps， 补点常识吧 basic things https://www.youtube.com/watch?v=AbyHtfDG8ME light luminous object transparent, translucent and opaque objects light travels a straight way occlusion cause shadowsoft shadow https://blog.demofox.org/2017/07/01/why-are-some-shadows-soft-and-other-shadows-hard/ soft shadow 并不是简单的边缘blur, 从形成原理上看umbra和距离光源的远近还有光源的大小都有关系 The math behind shadow mapping state of art projection shadow simply apply this matrix to the objects that should cast shadows on the plane π, and render this projected object with a dark color and no illumination. 考虑可能存在的问题： 阴影绘制在了平面的下面 --> 绘制顺序 or shadow map ground plane有边界，阴影绘在了边界外 --> stencil 光源处于shadow caster和receiver之间导致anti-shadow --> projection with clipping soft shadow 面光源采样得到一个punctual light, 渲染阴影，sum and average 通过filtering去blur hard shadow renders the silhouette edges with gradients that go from dark in the center to white on the edges projective texture mapping the occluder is rendered in black from the light’s viewpoint into an otherwise white texture. 以上两个projection的方法存在的问题： identify which objects are occluders and which are their receivers occluding objects cannot shadow themselves shadow volume the count is incremented as a ray passes through a frontfacing triangle of a shadow volume and decremented on leaving through a backfacing triangle. 两个pass： 一个pass只画front face，更新stencil buffer +1 一个pass只画back face，更新stencil buffer-1 存在的问题： 每个三角面片都要生成一个shadow volume计算量太大 受视角方向和光照方向影响很大 shadow maps basic principle from the light's point of view. texture DEPTH textures are usually of 24bits but they could be of 32bits encode the depth as a color //coverts a value from [0..1] into RGBA vec4 PackDepth32( in float depth ) { depth *= (256.0*256.0*256.0 - 1.0) / (256.0*256.0*256.0); vec4 encode = fract( depth * vec4(1.0, 256.0, 256.0*256.0, 256.0*256.0*256.0) ); return vec4( encode.xyz - encode.yzw / 256.0, encode.w ) + 1.0/512.0; } //coverts a RGBA into a float [0..1] float UnpackDepth32( in vec4 pack ) { float depth = dot( pack, 1.0/vec4(1.0, 256.0, 256.0*256.0, 256.0*256.0*256.0) ); return depth * (256.0*256.0*256.0) / (256.0*256.0*256.0 - 1.0); } shadow view --> shadowmap camera viewprojection matrix directional light orthographic view spot light perspective view poInt light cube map, 6 times perspective view reprojecting to shadow map when projecting a point using a projection matrix the result is in homogeneous coordinates, and we need to divide by the resulting .w to pass to clip-space coordinates. comparing depth dx11 sampleCmp 可以在采样的时候进行比较输出[0,1]的值 shadow map problems and solutions shadow acne slope scale bias Bias根据物体的normal和光照方向夹角决定，夹角越小，bias越小。 normal oﬀset bias 预先将物体的position延normal方向移动一个bias，bias和normal和光方向夹角成正比。 light leaks / peter panning front face culling perspective aliasing and projective aliasing 离viewer更近的区域在shadow map使用更多的采样 增大shadow map的resolution matrix-warping techniques 更改light的camera的参数 PCM(Perspective Shadow Maps) Light Space Perspective Shadow Maps(LiPSM) Trapezoidal Shadow Maps(TSM) cascade shadow 软阴影 PCF(Percentage-Closer Filtering) retrieving multiple samples from a shadow map and blending the results, to ﬁnd the percentage of the samples taken that are visible to the light. PCF会考虑以下几个variations 采样范围大小 采样数 采样点如何选取 采样结果权重 通常，采样randomly rotated Poisson distribution可以得到比较好的效果。 PCSS(Percentage-Closer Soft Shadows) 基于的主要假设是the average blocker is a reasonable estimate of the penumbra size. The average distance of these occluders from the location is used to determine the sample area width. The width of the surface area to the sample grows as the average occluder gets farther from the receiver and closer to the light. filtered shadow map VSM(Variance Shadow Map) 基本假设 receiver是一个平面。 基本原理 得到一个an upper bound on the visibility percentage of the receiver. 为了提升PCF的第三步的效率。 这个不等式理论上只有t在均值的右侧才正确。 PCSS第一步中的the average depth of blockers是如何近似的？ 如何得到average信息 MIPMAP and Summed Area Table (SAT) 优点 VSM can work with just a single, high-quality sample to determine the entire area’s eﬀect and produce a smooth penumbra 缺点 two or more occluders cover a receiver and one occluder is close to the receiver. 就是大多数occluders没有遮挡，但是有一个遮挡了，因为是求平均，所以会出现light bleeding (a.k.a. light leaks). CSM (Convolution Shadow Mapping) & ESM(Exponential Shadow Map) 把shadow函数用幂函数来建模： 然后用convolution来做filtering，这个filtering过的值就不是非0即1，有了中间值即soft shadow. Moment Shadow Mapping 基本思路 Use higher order moments to represent a distribution 基本原理 矩 缺点 Costly storage (might be fine) Costly performance (in the reconstruction) SDF(Signed Distance Field) 基本原理 不同的k决定的阴影有多soft float softshadow( in vec3 ro, in vec3 rd, float mint, float maxt, float k ) { float res = 1.0; for( float t=mint; t 优点 Fast High quality 缺点 Need precomputation Need heavy storage Artifact 复杂几何下产出的banding effects volumetric shadow technique transparency depth map The transparent objects are rendered to it, and the closest depth and color or alpha coverage is stored. 缺点是透明物体的自阴影实现不了。 deep shadow maps each shadow-map texel stores a function of how light drops oﬀ with depth. This function is typically approximated by a series of samples at diﬀerent depths, with each sample having an opacity value. 每个shadow map pixel 存若干个深度值和alpha。 opacity shadow maps，adaptive volumetric shadow maps 基本都是在deep shadow maps的基础上做了一些延伸和拓展。 var gitalk = new Gitalk({ clientID: '2eb19afceda708b27e64', // GitHub Application Client ID clientSecret: '36aedb5a30321626a8631689fee5fafd5929f612', // GitHub Application Client Secret repo: 'book', // 存放评论的仓库 owner: 'user', // 仓库的创建者， admin: ['user'], // 如果仓库有多个人可以操作，那么在这里以数组形式写出 id: location.pathname, // 用于标记评论是哪个页面的，确保唯一，并且长度小于50 }); gitalk.render('gitalk-container'); // 渲染Gitalk评论组件 Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-06-14 08:40:18 "},"shadow/assignment/assignment.html":{"url":"shadow/assignment/assignment.html","title":"games202 shadow assignment","keywords":"","body":"Games202 shadow assignment1 basic shadow 1 sample PCF 50 samples with uniform disk distribution 50 samples with Poisson distribution PCSS Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-17 20:08:29 "},"ao/resource.html":{"url":"ao/resource.html","title":"AO","keywords":"","body":"Resources Real-Time Rendering chapter 11.3 11.4 RT NV 2020 Real-Time Ray-Traced Ambient Occlusion of Complex Scenes using Spatial Hashing SDF SIG 2015, Dynamic Occlusion with Signed Distance Fields Screen Space HBAO, Image-Space Horizon-Based Aambient Occlusion HBAO, 知乎论文复现 HBAO+ GTAO, SIG16 talk Practical Real-Time Strategies for Accurate Indirect Occlusion SSDO, Approximating Dynamic Global Illumination in Image Space Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-04-20 11:40:17 "},"ao/ao_summary/ao_summary.html":{"url":"ao/ao_summary/ao_summary.html","title":"Real-Time AO Summary","keywords":"","body":"Real-Time Ambient Occlusion(AO) Summary why can calculate AO separately assumptions deeper mind what is AO definition visibility function interreflections Precomputed Ambient Occlusion sampling data storage large-scale AO Dynamic Computation of Ambient Occlusion 简化模型 SDF and cone tracing voxel based screen space accumulation Screen-Space Methods screen-space ambient occlusion (SSAO) volumetric based horizon-based ambient occlusion (HBAO) ground-truth ambient occlusion (GTAO) Directional Occlusion AO不适用的场景 Solutions 非平行光 glossy BRDF screen space directional occlusion (SSDO) why can calculate AO separately AO的核心思想是把visibility计算和lighting计算分开，降低render equation计算的复杂度。 assumptions incident indirect lighting is constant diffuse materials deeper mind 为什么把cos带上，实际是转换成在投影单位圆上的积分 what is AO definition ambient occlusion a cosine-weighted percentage of the unoccluded hemisphere, 半球上的结合cos权重的归一化积分（因为带了cos所以归一化要除以 pi）。 bent normal 考虑到遮挡关系，如果用a cosine-weighted average of unoccluded light directions作为shading的normal来使用，会得到更加准确的光照计算结果。 visibility function 对于室外，室内等不同场景，visibility function的定义决定了AO的质量和性能。 ambient obscurance The value of ρ (l) is 0 at an intersection distance of 0 and 1 for any intersection distance greater than a speciﬁed distance d_max , or when there is no intersection at all. 就是在某个方向0-d_max范围内对应vis函数的值从1到0过渡。 这个虽然不是physically correct, 但效果已经还不错了，因为限制了d_max，所以性能上也会好很多，但是d_max的值需要人为设定。 interreflections AO 和 GI 最大的一个不同就是考不考虑物体之间的相互反射。 如果有遮蔽，vis = 0，那就忽略了occluder的reflection，使得有些地方过黑。 ambient obscurance 可以稍微缓解下这个问题 近似考虑interrelfections under diﬀuse illumination, the surface locations visible from a given location tend to have similar radiance. offline path tracing perform full, oﬄine path tracing for a number of scenes, each lit by a uniformly white, inﬁnitely distant environment map to obtain occlusion values. ﬁt cubic polynomials to approximate the function f that maps from the ambient occlusion value k_A and subsurface albedo ρ_ss to the occlusion value k_A′, which is brightened by the interreﬂected light. 用三次多项式去拟合AO的函数。 Precomputed Ambient Occlusion 基本的思想是基于RT, 适用于静态物。 sampling Monte Carlo importance sampling the distribution of ray directions is cosine weighted. data storage ambient occlusion ﬁeld model how the ambient occlusion value changes with distance from the object with a reciprocal of a quadratic polynomial and its coeﬃcients are stored in a cube map. ambient occlusion volume 三维贴图，存储ambient occlusion factors, and optionally the bent normal. large-scale AO a top-down view and process the resulting depth map to compute large-scale occlusion. 根据neighboring depth samples来计算AO. Dynamic Computation of Ambient Occlusion 动态物的AO没办法实时用RT的方法去做，需要做一些简化来更快的近似计算出来。 简化模型 modeling the surface as a collection of disk-shaped elements placed at the mesh vertices 之所以选择disk，是因为disk之间的遮挡关系计算是可控的。 approximate the occluding geometry as a collection of spheres 个人感觉这两个方法商用起来都有点费劲，还不如直接拿静态物的occluder来用。 SDF and cone tracing 最终的occlusion factor = cone tracing过程中的最小立体角 / cone tracing的最初立体角 a set of cones, covering the entire hemisphere global SDF & local SDF voxel based voxel GI 的时候顺带做。 screen space accumulation 对于每个object, 给出一个occlusion影响范围，在这个范围内计算物体对每个像素的occlusion影响，转换成 a proper spherical harmonic value is added to an oﬀscreen buﬀer. After accumulating visibility for all the occluders, the values in the buﬀer are exponentiated to get the ﬁnal. Screen-Space Methods screen-space ambient occlusion (SSAO) 如果已知normal，可以在半球上做结果更准确。 原算法忽略了cos项，觉得可以以cos的概率去随机选取采样点。 volumetric based where X is a three-dimensional, spherical neighborhood around the point, 考虑周围三维空间的遮挡关系，利用三维的遮挡体积比例关系计算occlusion factor. horizon-based ambient occlusion (HBAO) 基于的假设是，the data in the z-buﬀer represents a continuous heightﬁeld, 连续了才能用角度近似。 本质上是用未被遮挡的立体角除以整个半球的立体角作为occlusion factor. W这个attenuation function可以是基于距离的衰减函数。 t这个角度是该点的切平面和视线的切平面的夹角，那个黑色箭头是视线方向。 至于积分可以转换为离散采样等处理之后详细的再说说。 ground-truth ambient occlusion (GTAO) 为什么敢号称ground-truth HBAO忽略了(n dot L)项，并且还加了一项ad hoc attenuation. GTAO introduces the missing cosine factor, removes the attenuation function, and formulates the occlusion integral in the reference frame around the view vector. basic theory 注意到HBAO的分母是2 pi，但GTAO是pi, 原因就差在一个cos项上。 Directional Occlusion AO不适用的场景 会议下AO做的假设，就可以看出，AO不适用于 large area light & punctual light glossy BRDF Solutions 非平行光 light cone 和 visibility cone 求交 glossy BRDF the approximate BRDF is deﬁned as a sum of spherical Gaussians assume that the visibility function is constant across the entire support of each spherical Gaussian screen space directional occlusion (SSDO) 采样各个点，如果遮蔽，计算遮蔽处的间接光照。 这样想的话 不是 AO * direct_lighting + DO 才是最终的光照结果。 Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-06-20 17:04:14 "},"aa/resource.html":{"url":"aa/resource.html","title":"AA","keywords":"","body":"Resources TAA talk Dynamic Temporal Antialiasing in Call of Duty: Inﬁnite Warfare Temporal Antialiasing in Uncharted 4 16 Inside GDC 14 Unreal 22 new blog of TAA implementation https://github.com/playdeadgames/temporal https://github.com/h3r2tic/rtoy-samples/blob/master/assets/shaders/taa.glsl https://github.com/Unity-Technologies/Graphics/blob/master/com.unity.render-pipelines.high-definition/Runtime/PostProcessing/Shaders/TemporalAntialiasing.hlsl https://github.com/TheRealMJP/MSAAFilter/blob/master/MSAAFilter/Resolve.hlsl https://github.com/turanszkij/WickedEngine/blob/master/WickedEngine/shaders/temporalaaCS.hlsl https://gist.github.com/Erkaman/f24ef6bd7499be363e6c99d116d8734d https://github.com/GameTechDev/TAA/blob/main/MiniEngine/Core/Shaders/TAAResolve.hlsl https://github.com/PanosK92/SpartanEngine/blob/master/Data/shaders/temporal_antialiasing.hlsl https://github.com/NVIDIA/Q2RTX/blob/master/src/refresh/vkpt/shader/asvgf_taau.comp https://ziyadbarakat.wordpress.com/2020/07/28/temporal-anti-aliasing-step-by-step/ FXAA FXAA算法演义 Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-04-21 13:46:07 "},"aa/aa_summary/aa_summary.html":{"url":"aa/aa_summary/aa_summary.html","title":"Real-Time AA Summary","keywords":"","body":"Real-Time antialiasing summary why AA sampling and filtering theory 熟悉的奈奎斯特采样定理 reconstruction resampling screen-based antialiasing more samples sampling patterns Morphological Methods why AA what cause aliasing Aliasing occurs when a signal is being sampled at too low a frequency sampling and filtering theory 想起了遥远的信号与系统~ 熟悉的奈奎斯特采样定理 要想信号可以被原样还原, the sampling frequency has to be more than twice the maximum frequency of the signal to be sampled, 否则还原出来的信号会混叠。 frequency 是 1 / T, 时域里变化周期的倒数。 但是rendering里的三维空间is normally never band-limited when rendered with point samples, 所以完全解决走样问题是几乎不可能的。 reconstruction resampling downsampling and upsampling screen-based antialiasing more samples 基于的宗旨基本上都是每个pixel多一些samples. SuperSampling AA 渲一个更大分辨率的，再下采样。 MSAA 每个物体对应一个像素的pixel shader只执行一次，但是一个pixel对应多个coverage samples，各个sample各取所需。 TAA 每帧相机做一些jitter，利用上一帧或前几帧的渲染结果，变相的也是多了一些samples，但是对于每一帧来说sampling的开销并没有增多。 sampling patterns 研究表明，人眼对于near-horizontal and near-vertical edges更为敏感，其次是45度对角。 RGSS（rotated grid） Halton sequence generates samples in space that appear random but have low discrepancy Quincunx sharing samples among pixels FLIPQUAD Morphological Methods 基于图像的后处理操作。 FXAA (fast approximate antialiasing) 判定哪些像素是边缘 sharp changes in brightness. 边缘像素做blend SMAA (subpixel morphological antialiasing) A logical development of the FXAA algorithm. This technique not only blurs the contrast points, but also uses a kind of logic – it finds and recognizes patterns in the form of lines, curves, boundaries of objects, and blurs them in the direction of these lines. Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-08-15 17:34:59 "},"aa/taa/taa.html":{"url":"aa/taa/taa.html","title":"TAA Implementation Summary","keywords":"","body":"TAA Implementation vs. DLSS antialiasing aliasing type of rendering aliasing geometry aliasing shading aliasing antialiasing 熟悉的奈奎斯特采样定理 reconstruction screen space antialiasing more samples SSAA (Super Sampling Antialiasing) MSAA (Multisampling Antialiasing) vs EQAA(Enhanced Quality Antialiasing) TAA Morphological Methods FXAA(Fast Approximate Antialiasing) SMAA(Subpixel Morphological Antialiasing) TAA pipeline jitter your view frustum motion vector precache scene depth and color(color transformation) precache tone mapping linear --> YCoCg history sampling motion vector sampling history filtering history rectification neighborhood bounding box of current frame rectification current frame sampling current filtered color sharpen blend ratio tone mapping sharpen others transparent object / particles small object blurring flickering art of balancing DLSS why talking with TAA features performance theory problem single image super-res multi-frame super-res pipeline input sub-pixel jitter sample pattern frosbite DLSS integration antialiasing aliasing aliasing occurs when a signal is being sampled at too low a frequency type of rendering aliasing geometry aliasing 对几何覆盖函数的采样不足 shading aliasing 对渲染方程的采样不足 antialiasing 熟悉的奈奎斯特采样定理 要想信号可以被原样还原, the sampling frequency has to be more than twice the maximum frequency of the signal to be sampled, 否则还原出来的信号会混叠。 但是rendering里的三维空间 is normally never band-limited when rendered with point samples, 所以完全解决走样问题是几乎不可能的。 reconstruction screen space antialiasing more samples 基于的宗旨基本上都是每个pixel多一些samples. SSAA (Super Sampling Antialiasing) each sample has to run through a pixel shaderMSAA (Multisampling Antialiasing) vs EQAA(Enhanced Quality Antialiasing) the pixel shader is evaluated only once for each object fragment applied to the pixel. TAA Morphological Methods FXAA(Fast Approximate Antialiasing) find edge (based on color) find line (horizon or vertical) filtering SMAA(Subpixel Morphological Antialiasing) find edge (based on color, depth, normal, primitiveID...) find line filtering TAA pipeline post process highlight_object 和 DOF之后。 jitter your view frustum low discrepancy sequence the proportion of points in the sequence falling into an arbitrary set B is close to proportional to the measure of B. https://en.wikipedia.org/wiki/Low-discrepancy_sequence adjust projection matrix motion vector static dynamic precache scene depth and color(color transformation) precache tone mapping linear --> YCoCg a simple transformation of an associated RGB color space into a luma value (denoted as Y) and two chroma values called chrominance green (Cg) and chrominance orange (Co). history sampling motion vector sampling 当镜头的移动时，可能会导致物体的遮挡关系发生变化，比如一个远处的物体原来被前面的物体遮挡住，现在因为镜头移动而忽然出现，这时采样 Motion 偏移得到的位置，上帧中其实是没有渲染的数据的。因此为了得到更加平滑的数据，可以在当前像素点周围判断深度，取距离镜头最近的点位置，来采样 Motion Vector 的值，这样可以减弱遮挡错误的影响。 history filtering Resampling blur happens when motion causes target pixels to reproject to fractional pixel locations in the previous frame. https://zhuanlan.zhihu.com/p/450936588 history rectification neighborhood bounding box of current frame rectification clamping clipping current frame sampling current filtered color sharpen luma contrast 越小减少filtering的作用 blend ratio luma diff velocity velocity的大小 velocity偏离pixel中心多少 tone mapping YCoCg --> linear HDR -> LDR sharpen others transparent object / particles small object blurring moving character using last render result as previous input but not previous taa output using more result of current frame flickering https://zhuanlan.zhihu.com/p/71173025 如果上一帧深度与当前帧深度差距大，那就可以顺理成章的判断出上一帧与当前帧在这个像素点上产生了Flicker，这时候直接强行取消Clamp，使两像素融合到一起，也就不会因为Clamp而产生闪烁了。 art of balancing DLSS why talking with TAA antialiasing TAA upsampling features performance https://developer.nvidia.com/rtx theory problem single image super-res multi-frame super-res pipeline input color buffer any format motion vectors RG32_FLOAT / RG16_FLOAT depth buffer exposure value (for HDR) previous output buffer(optional) only RGBA16F sub-pixel jitter sample pattern halton pattern phase TAA 8 samples DLSS Total Phases = Base Phase Count * (Target Resolution / Render Resolution) ^ 2 frosbite DLSS integration motion vector need to be accurate pixel space not uv space，可以使用给一个motion vector scale 为render resolution来缩放 need to be accurate every object must have one，(1, 1)怕是不兼容 texture mip bias 我们引擎里的lod bias， 原来lod 1.2， bias 0.5， 则最终采用mip map level 为1.7. 又因为DLSS是渲了一个更小的分辨率，所以尽量让LOD减小以增加精度。 post effects and depth buffer strand hair rasterizer other gotchas Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-10-05 11:43:45 "},"aa/specular_aa/specular_aa.html":{"url":"aa/specular_aa/specular_aa.html","title":"Specular AA","keywords":"","body":"Specular AA problem reference basic principle NV 16 19 implementation problem reference NV 16 Filtering Distributions of Normals for Shading Antialiasing 19 Improved Geometric Specular Antialiasing shadertoy realization https://www.shadertoy.com/view/WssyR7 basic principle NV 16 filters a distribution of microfacet normals in the domain of microfacet slopes by estimating the filtering kernel using derivatives of a halfway vector between incident and outdoing directions. 在一个很小的面积内对BSDF做filtering 基于假设：积分区域远小于eye和light source到surface point的距离，上述公式可以简化为 Fresnel 和 Geometry项都属于[0,1]范围，变化较为平缓，可视为常数。 problem filters a distribution of microfacet normals in the domain of microfacet slopes by estimating the filtering kernel using derivatives of a halfway vector between incident and outdoing directions. 越接近gazing angle，hz越小，误差越大。 19 estimates the derivatives in a projected halfvector space instead of slope space optimization for deferred shading implementation forward previous improved Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-05-16 19:41:22 "},"dlss/resource.html":{"url":"dlss/resource.html","title":"DLSS","keywords":"","body":"Resources NV DLSS Github SDK Document PDF GTC2020, DLSS 2.0 知乎 文刀秋二 Frosbite Integrating DLSS to the Frostbite engine Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-08-03 17:00:26 "},"dlss/dlss/dlss.html":{"url":"dlss/dlss/dlss.html","title":"DLSS Summary","keywords":"","body":"DLSS resources RTX GPU input pipeline mip-map bias motion vector sub-pixel jitter jitter sample pattern exposure parameter frosbite DLSS integration resources programming guide RTX GPU https://developer.nvidia.com/rtx input color buffer any format motion vectors RG32_FLOAT / RG16_FLOAT depth buffer exposure value (for HDR) previous output buffer(optional) only RGBA16F pipeline mip-map bias 我们引擎里的lod bias， 原来lod 1.2， bias 0.5， 则最终采用mip map level 为1.7. 又因为DLSS是渲了一个更小的分辨率，所以尽量让LOD减小以增加精度。 motion vector pixel space not uv space，可以使用给一个motion vector scale 为render resolution来缩放 need to be accurate every object must have one，(1, 1)怕是不兼容 sub-pixel jitter jitter sample pattern halton pattern phase TAA 8 samples DLSS Total Phases = Base Phase Count * (Target Resolution / Render Resolution) ^ 2 exposure parameter frosbite DLSS integration basic integration motion vector need to be accurate texture mip bias post effects and depth buffer strand hair rasterizer other gotchas Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-08-03 16:41:02 "},"dlss/dlss_implementation/dlss_implementation.html":{"url":"dlss/dlss_implementation/dlss_implementation.html","title":"DLSS Implementation","keywords":"","body":"DLSS Implementation 启动 DLSS not available on this hardware/platform 画面一直抖动，用ctrl + alt + F12 debug看jitter并没有生效 启用dlss有点模糊 pipeline motion vector resolve depth upsampling exposure texture 对于motion vector 很小的时候会有残影 render target 重新创建的机制问题 抖动，粒子bug quality 启动 DLSS not available on this hardware/platform 需要把dll拷贝到客户端的启动目录下，之后根据客户端配置放到统一路径下 画面一直抖动，用ctrl + alt + F12 debug看jitter并没有生效 因为每一帧都重新initializeDLSSFeature，可能导致dlss并没有真正生效。 只在dlss配置有更新， or rende_target resolution有变或者最终的display resolution有更改时才重新initialize. 启用dlss有点模糊 校正motion vector 把相机的位置作为新的世界坐标系原点 但一些屏幕上很小的动态物缓慢运动时还是会糊 考虑是不是低LOD下的动画精度不够 pipeline motion vector resolve 在传入dlss之前，motion vector要做一些处理 部分静态物的motion vector 默认给了(1, 1), 需要根据前后帧相机算出静态物的motion vector dlss 需要的motion vector 是 prev_uv - current_uv，这个要弄对，我们引擎原先的mv正好是相反的 dlss需要的motion vector 是以像素为单位的，不是uv，所以要么在shader里给motion vector乘以resolution，或者DLSS参数的InMVScaleX, InMVScaleY要设置为resolution的值 depth upsampling 后处理在dlss pass 之后的depth需要upsampling到display resolution, 目前采用最简单的linear upsampling，但讲道理可能会有问题，比如motion vector之类的，需要验证。 exposure texture 我们游戏的关卡部分开了自动曝光，部分没开，试了下， exposure texture 如果给nullptr也不会有什么影响，可能底层给了默认值。 对于motion vector 很小的时候会有残影 P界面展示角色的时候，背景是很暗的纯色，人物有细微的动作，motion vector很小，出现残影。 exposure texture还是要给，哪怕是一张默认的图，不然会有ghosting, 在一些场景里。 最后发现刀盾还是motion vector为0导致的，因为之前TAA就碰到的一个问题，ammo的previous position render target 重新创建的机制问题 DLSS开关，包括使用特定模式都会导致 RT 的 resolution 切换，这里要注意render target的切换以及其对其他pass的影响。 抖动，粒子bug 抖动 -- rigid instance 更新position有bug 粒子 -- viewport设置 quality 1080p scale ratio要达到0.7效果才还可以 4k balance模式下scale ratio在0.6左右，效果可以 昊京城关卡从56帧到72，提升10多帧，dlss耗时1.8ms Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-08-03 16:22:17 "},"character/resource.html":{"url":"character/resource.html","title":"Character","keywords":"","body":"Resources Solutions NEXT GENERATION CHARACTER RENDERING, GDC13, Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2023-06-12 12:05:39 "},"character/subsurface/resource.html":{"url":"character/subsurface/resource.html","title":"Subsurface(Skin)","keywords":"","body":"Resources Blogs GPU Gems3 https://www.cnblogs.com/KillerAery/p/15719431.html https://zhuanlan.zhihu.com/p/42433792 Papers Courses Extending the Disney BRDF to a BSDF with Integrated Subsurface Scattering (Brent Burley) Approximate Reflectance Profiles for Efficient Subsurface Scattering, 2015 Implementations UE https://github.com/EpicGames/UnrealEngine/blob/4.27/Engine/Shaders/Private/SubsurfaceBurleyNormalized.ush#L1163 Unity https://github.com/Unity-Technologies/Graphics/blob/v10.8.0/com.unity.render-pipelines.high-definition/Runtime/Material/SubsurfaceScattering/SubsurfaceScattering.compute#L248 Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2023-06-12 12:07:59 "},"character/hair/resource.html":{"url":"character/hair/resource.html","title":"Hair","keywords":"","body":"Resources 总结型文档 知乎，毛发渲染总结 Important Papers Kajiya-Kay 1989年的论文《rendering fur with three dimensional textures》 https://www.cs.drexel.edu/~david/Classes/CS586/Papers/p271-kajiya.pdf Marschner 在SIGGRAPH 2003中的论文《Light Scattering from Human Hair Fibers》 http://www.graphics.stanford.edu/papers/hair/hair-sg03final.pdf Presentations GDC 2004中ATI的分享《Hair Rendering and Shading》 http://web.engr.oregonstate.edu/~mjb/cs519/Projects/Papers/HairRendering.pdf d’Eon的《An Energy-Conserving Hair Reflectance Model》： http://www.eugenedeon.com/wp-content/uploads/2014/04/egsrhair.pdf Pixar 《A Data-Driven Light Scattering Model for Hair》 https://graphics.pixar.com/library/DataDrivenHairScattering/paper.pdf Unreal在SIGGRAPH 2016 《Physically Based Hair Shading in Unreal》 https://blog.selfshadow.com/publications/s2016-shading-course/karis/s2016_pbs_epic_hair.pdf Strand-based Hair Rendering in Frostbite, SIGGRAPH 2019 http://advances.realtimerendering.com/s2019/index.htm http://advances.realtimerendering.com/s2019/hair_presentation_final.pdf 知乎文章 https://zhuanlan.zhihu.com/p/336922296 UC Berkeley 《Physically-based Modeling and Rendering of Complex Visual Appearance》 2022 Siggraph Unity Probe-based lighting, strand-based hair system, and physical hair shading in Unity’s ‘Enemies’ Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2023-06-12 12:00:19 "},"texture/resource.html":{"url":"texture/resource.html","title":"Texture","keywords":"","body":"Resources Multiple Textures Texture Array DirectX11--深入理解与使用2D纹理资源 Bindless Texture DirectX12 Bindless Texture初探 Virtual Texture 浅谈virtual texture adaptive virtual texture rendering in farcry4 Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-03-18 13:44:11 "},"texture/multiple_textures/multiple_textures.html":{"url":"texture/multiple_textures/multiple_textures.html","title":"Multiple Textures","keywords":"","body":"DirectX multiple textures texture array Texture2DArray gTexArray : register(t0); float4 PS(VertexPosHTex pIn) : SV_Target { float4 texColor = gTexArray.Sample(gSam, float3(pIn.Tex, gTexIndex)); return texColor; } inline UINT D3D11CalcSubresource(UINT MipSlice, UINT ArraySlice, UINT MipLevels ) { return MipSlice + ArraySlice * MipLevels; } bindless texture 与传统的TextureArray不同之处在于，Shader读取时完全不对贴图在物理内存中排列有任何要求，这就意味着我们可以在一个队列中放入任意数量，任意大小，任意格式的贴图，其自由度要远高于传统的TextureArray。 Texture2D gDiffuseMap[num] : register(tX, spaceX); 这里为啥uv是乘以3采样的？？ virtual texture 基本思路是，会将纹理的mipmap chain分割为相同大小的tile或page,这里的纹理叫虚纹理，然后通过某种映射，映射到一张内存中存在的纹理，这里的纹理是物理纹理，在游戏视野发生变化的时候，一部分物理纹理会被替换出去，一部分物理纹理会被加载。 Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-03-14 22:51:18 "},"pipeline/visibility/resource.html":{"url":"pipeline/visibility/resource.html","title":"Dynamic Visibility","keywords":"","body":"Resources early-z、z-culling、hi-z、z-prepass到底是什么 文章里把z-prepass写成z-perpass了 Hill11, Practical, Dynamic Visibility for Games, hierarchical z-buffer Hierarchical-Z map based occlusion culling intel software occlusion culling GPU driven occlusion culling Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-03-15 19:37:15 "},"pipeline/visibility/dynamic_visibility_draft/draft.html":{"url":"pipeline/visibility/dynamic_visibility_draft/draft.html","title":"Dynamic Visibility Draft","keywords":"","body":"dynamic visibility solutions Static Potentially Visible Sets (PVSs) the world is discretised in some way (BSP, grid, etc.) and the binary visibility from each sector (leaf node, cell or cluster respectively) to all other sectors is pre-computed and stored. 动态物和一些可破坏物不在遮挡的计算范畴。 Hardware Occlusion Queries rendering the depth of a subset (or a simplified representation) of the scene – the occluders – and then rasterising (without depth writes，with occlusion query) the bounds of objects, or groups of objects. 古老的技术，把物体的bounding box传入得到物体是否被遮挡的结果 Hierarchical Z Buffer Render Occluder Depth Create a Depth Hierarchy Test Object Bounds 根据投影到screen上的面积来决定depth map的mip level sampler2D sHZB : register(s0); float4 main(INPUT input) : COLOR0 { float4 sbox = input.sbox; float level = input.data.x; float min_z = input.data.y; bool visible = input.data.z; float4 samples; samples.x = tex2Dlod(sHZB, float4(sbox.xy, 0, level)).x; samples.y = tex2Dlod(sHZB, float4(sbox.zy, 0, level)).x; samples.z = tex2Dlod(sHZB, float4(sbox.xw, 0, level)).x; samples.w = tex2Dlod(sHZB, float4(sbox.zw, 0, level)).x; // Modulate culling with depth test result float max_z = max4(samples); visible *= min_z Process the results 根据得到的visibility结果来决定是否剔除物体。 Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-03-21 20:27:52 "},"pipeline/cs/resource.html":{"url":"pipeline/cs/resource.html","title":"Compute Shader","keywords":"","body":"Resources Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-03-21 20:29:00 "},"pipeline/gpudriven/resource.html":{"url":"pipeline/gpudriven/resource.html","title":"GPU Driven Rendering","keywords":"","body":"Resources prior knowledge hierarchical z-buffer bindless texture, virtual texture deferred texturing cpu occlusion culling steam compaction Blelloch, Prefix Sumsand Their Applications GPU Gems 3, Chapter 39. Parallel Prefix Sum (Scan) with CUDA compute shader directX instructions gather4 StructuredBuffer & AppendStructuredBuffer RWBuffer RWTexture2D DrawIndexedInstanced vs DrawIndexInstancedIndirect vs MultiDrawIndexedInstancedIndirect dx12 multi-indirect draw AMD driver NVIDIA driver presentations siggraph15, @ ubisoft 中文解读 上面的pdf没有说明，对于第一次接触的人看起来会比较吃力，可以先看这篇中文解说，更好接受。 gdc16, @ EA gdc18, TerrainRenderingFarCry5 @ ubisoft dragons conference 18, GPU driven Occlusion Culling 有对应的presentation pdf 和 demo source code 一些实现细节的blog part1 一些实现细节的blog part2 vulkan guide GPU driven rendering guide Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-03-31 15:30:13 "},"pipeline/gpudriven/oc/oc.html":{"url":"pipeline/gpudriven/oc/oc.html","title":"GPU Driven Occlusion Culling","keywords":"","body":"GPU Driven Occlusion Culling https://interplayoflight.wordpress.com/2018/05/25/gpu-driven-rendering-experiments-at-the-digital-dragons-conference/ 18年这个course的一些notes和thoughts main thoughts steps Occlusion buffer Hierarchical-Z mip chain Prop visibility calculation stream compaction MultiDrawInstancedIndirect batching mesh LOD material texture 最后附上一个针对每一步输入输出整理的XMind main thoughts using a compute shader to perform the occlusion tests producing a list of visible props consuming on the GPU to avoid rendering occluded objects using instance rendering to render the props steps Occlusion buffer render the depth of all main occluders to the occlusion buffer without pixel shader Hierarchical-Z mip chain create a Hierarchical-Z mip chain of the occlusion buffer, using the max operator to produce each mip level using a compute shader to do the downsampling void downscale(uint3 threadID : SV_DispatchThreadID) { if (all(threadID.xy gather 不支持 mip level 参数, 且只有shader model 5支持，还是用4 texture reads Prop visibility calculation packed data for instances of props in a Structured buffer world transformation axis aligned bounding box choose whether perform frustum culling compute shader to calculate visibilities 根据物体的boundingbox投影到clip space的面积大小，决定采样那一个mip level，将bdbox的八个corner的最小深度和采样得到的最大深度对比，如果最小深度>采样深度，则物体被遮挡。 for (int i = 0; i 0) && all(minXY = 0.001 ) { float mip = ceil(log2(max(size.x, size.y))); // 这里是计算mip level的地方 mip = clamp(mip, 0, MaxMipLevel); // Texel footprint for the lower (finer-grained) level float level_lower = max(mip - 1, 0); float2 scale = exp2(-level_lower); float2 a = floor(boxUVs.xy*scale); float2 b = ceil(boxUVs.zw*scale); float2 dims = b - a; // Use the lower level if we only touch stream compaction save prop visibility result as bool instanceFlagsData[threadID.x] = predicate; parallel prefix scan 如果第i个instance可见(input[i] > 0), 把这个instance的数据拷贝给压缩结果的第Output[i]个data. stream compaction 给定一个序列，如何得到前i-1个数据的和 每次将相邻两个值求和 //perform reduction for (d = NoofDrawcalls >> 1; d > 0; d >>= 1) { GroupMemoryBarrierWithGroupSync(); if (tID 再每次将序列一分为二，对比最后两个数值 以上计算可以用compute shader 并行计算，每一层需要做一次同步 //perform downsweep and build scan for (d = 1; d >= 1; GroupMemoryBarrierWithGroupSync(); if (tID 为啥最多2048个数据呢，因为一个线程组最多1024个线程，每个线程计算2个数的和，最多可以计算2048个数据。 超过2048个数据怎么办 每2048个数据使用一个compute shader thread group计算组内的累加和，然和把最大的和记到另外的数组里，之后再用一个pass, 对每个group里的数据分别加上之前所有组的最大的和 MultiDrawInstancedIndirect DX12 直接支持void ExecuteIndirect( ID3D12CommandSignature *pCommandSignature, UINT MaxCommandCount, ID3D12Resource *pArgumentBuffer, UINT64 ArgumentBufferOffset, ID3D12Resource *pCountBuffer, UINT64 CountBufferOffset ); DX11 使用NVIDIA 或者 AMD 的 driver extension nv 和 amd 还是需要把vertex 数据拍到一起 nvapiNvAPI_D3D11_MultiDrawIndexedInstancedIndirect( d3dImmediateContext, drawCount, //drawCount, renderingContext.m_instanceArgsBuffer->GetBuffer(), 0, //alignedByteOffsetForArgs 5 * sizeof(UINT) //alignedByteStrideForArgs ); DX11 除了 NVIDIA 和 AMD，使用函数封装多个DrawIndexedInstancedIndirect 或者 把所有物体生成相同顶点数的cluster，再调用DrawIndexedInstancedIndirect for (UINT i = 0; i DrawIndexedInstancedIndirect( argumentsBuffer, i * 5 * sizeof(UINT) ); } batching mesh LOD mesh cluster 这里看了一个unity的demo里的实现，是将一个object的bounding box分成多个voxel，即一个个小的立方体，然后把所有vertex根据位置对应到不同的voxel. 然后再开始分配cluster，eg. 一个cluster 255个顶点，对于一个voxel，如果>=255个顶点，把前255个顶点分配给一个cluster，如果 int loopStart = min(currentVoxel.count, max(lastedVertex - currentVoxel.count, 0)); for (int j = 0; j a); currentPoints.Add(tri->b); currentPoints.Add(tri->c); } lastedVertex -= loopStart; for (int size = 1; lastedVertex > 0; size++) { int3 leftDown = max(voxelCoord - size, 0); int3 rightUp = min(voxelSize, voxelCoord + size); for (int x = leftDown.x; x a); currentPoints.Add(tri->b); currentPoints.Add(tri->c); lastedVertex--; if (lastedVertex material single constant buffer shader 里 PerObjectData数组，size=2，可支持动态大小 texture texture array bindless texture virtual texture 最后附上一个针对每一步输入输出整理的XMind GPU driven rendering.png Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-05-14 11:16:54 "},"pipeline/gpudriven/oc_implementation/oc_implementation.html":{"url":"pipeline/gpudriven/oc_implementation/oc_implementation.html","title":"Occlusion Culling Imlementation Minimal Set","keywords":"","body":"GPU Driven Occlusion Culling Minimal Set what is the minimal set process ID3D11DeviceContext::DrawIndexedInstancedIndirect 的 instance args作用 typedef struct D3D11_DRAW_INDEXED_INSTANCED_INDIRECT_ARGS { UINT IndexCountPerInstance; UINT InstanceCount; UINT StartIndexLocation; INT BaseVertexLocation; UINT StartInstanceLocation; } D3D11_DRAW_INDEXED_INSTANCED_INDIRECT_ARGS; 感觉StartIndexLocation, BaseVertexLocation 和 StartInstanceLocation 实际的绘制是没用到的, 如果不作为shader resource传入的话 https://docs.microsoft.com/en-us/windows/win32/api/d3d11/nf-d3d11-id3d11devicecontext-drawindexedinstanced https://docs.microsoft.com/en-us/windows/win32/api/d3d11/ns-d3d11-d3d11_draw_indexed_instanced_indirect_args https://docs.microsoft.com/en-us/windows/win32/api/d3d11/nf-d3d11-id3d11devicecontext-drawinstancedindirect 是有用到的，如果把所有物体的vertex buffer 和 index buffer 拍到了一起 定义了vertex buffer 的 各个elment 的stride 之后， 绘制每个instance对应的物体的时候，会根据 StartIndexLocation 和 BaseVertexLocation 来偏移到开始读数据的位置， 偏移是除以了stride之后的个数， 不是字节数。 StartInstanceLocation 是用来对 per instance data进行偏移的, 但一般用constant buffer把参数传进去。 The second buffer is needed only if the input layout that you use has elements that use D3D11_INPUT_PER_INSTANCE_DATA as the input element classification. 所以本质上如果所有object的vertex declaration都一样，或者vertex buffer 数据结构强行搞成一样(不存在的字段也占位)，是可以直接用这几个参数就可以绘制的。 但是有些物体可能只有一个uv参数，或者没有骨骼数据，如果强行占位的话，vertex buffer的空间会有点浪费。 这里有几种内存排布方式： AOS(array of struct) vertex的数据按照AOS在内存一个个排列，这样只需要把vertex的layout里每个字段的偏移设置正确，相同vertex declaration的object放到一个draw call. 但这样的问题是如果某个pass只需要position数据全部传入处理就比较麻烦了。 struct Vertex { float3 position; float3 normal; float2 uv; ... } SOA(struct of array) vertex的每个element作为一个数组存储，这里也有两种方式： 不同object的vertex的相同element的数据分别不连续的存在对应的数组里，但这样multi_draw_indirect没办法操作，因为没办法指定各个物体normals/uvs的起始offset.vertex1(all_positions, all_normals, all_uvs) | vertex2((all_positions, all_normals, all_uvs)) 所有object的vertex的相同element的数据都放到一个数组里vertex1_all_positions, vertex2_all_positions, vertex3_all_positions vertex1_all_nomarls, vertex2_all_normals, vertex3_all_normals 这里也有两种方式： 所有object都使用统一的vertex layout，不存在的数据就占位 虽然会有内存浪费，但是好处就是不用另外做处理，底层可以根据layout和offset获取数据。 不同object根据定义用不同的vertex layout 不会有内存浪费，但是每个vertex element的offset和这些element数据需要存在另外的buffer里传进去，manual索引。 我们采用的方法是 每个vertex element 创建一个单独的 buffer, 把所有物体的对应数据拍在一起，每个物体的每个vertex element记录下对应buffer 的 offset. DirectX debug device https://docs.microsoft.com/en-us/windows/win32/api/d3d11sdklayers/nf-d3d11sdklayers-id3d11infoqueue-setbreakonseverity https://walbourn.github.io/dxgi-debug-device/ This snippet ensures that a common but harmless warning message is suppressed in non-Production builds, and enables ‘break on’ functionality in Debug builds if there are any serious corruption/error/warning messages. ID3D11InfoQueue::SetBreakOnSeverity(D3D11_MESSAGE_SEVERITY_CORRUPTION, true) ID3D11InfoQueue::SetBreakOnSeverity(D3D11_MESSAGE_SEVERITY_ERROR, true) ID3D11InfoQueue::SetBreakOnSeverity(D3D11_MESSAGE_SEVERITY_WARNING true) DirectX api 里的各种offset， OMG 把vertex数据都拍到一起之后，所有相关的buffer offset都要更改。 byte offset https://docs.microsoft.com/en-us/windows/win32/api/d3d11/nf-d3d11-id3d11devicecontext-iasetindexbuffer void IASetIndexBuffer( ID3D11Buffer *pIndexBuffer, DXGI_FORMAT Format, UINT Offset ); Offset Type: UINT Offset (in bytes) from the start of the index buffer to the first index to use. 这里有特别说明是以字节为单位的offset. stride divided offset https://docs.microsoft.com/en-us/windows/win32/api/d3d11/nf-d3d11-id3d11devicecontext-drawindexed void DrawIndexed( UINT IndexCount, UINT StartIndexLocation, INT BaseVertexLocation ); StartIndexLocation Type: UINT The location of the first index read by the GPU from the index buffer. 这里没有特别说明就是以 字节/stride 为步长的offset. 其实我后来想了想，这样做是有他的逻辑在里面的。起始地址用字节，是因为不知道前面的内存里存了啥样的数据，不可能根据stride来。有了起始地址之后，我要索引一整块相同layout数据的某个数据的时候，就可以根据stride divided来了，这样可以根据一些序数来设置比较方便。 buffer里有部分数据是global的，即使关卡切换也只load一次 我们游戏里是有一部分数据是全局的，只load一次，还有一些数据是根据关卡来的，关卡切换就会重新load. 因为全局数据是先加载的，所以可以在buffer设置一个标记offset，标记这之后的数据都是非全局数据。这样如果关卡切换，buffer重置只需要将used标记重置到global的offset就可以，即内存分配从非global的地址开始。 赋值内存的几种方式 初始化的时候就给一个Initial data mapped锁住数据，再更新 updateSubResource 兼容之前的方式，同时支持两种pipeline 原来vertex buffer里的数据还需要作为shader resource传进去 https://docs.microsoft.com/en-us/windows/win32/api/d3d11/ns-d3d11-d3d11_buffer_desc https://docs.microsoft.com/en-us/windows/win32/api/d3d11/ne-d3d11-d3d11_bind_flag bind flag 需要支持两种 每个object的vertex element的byte offset 和 stride divided offset都要记录。 如果两种pipeline需要切换的时候，一些buffer需要释放，并且申请新的buffer作为存储。或者以后都统一成一种buffer分配方式。 合成一块buffer之后，buffer的max size要估计好 超过上限，会绘制出另外一种画风，我遇到过超限的时候，那个画面让我想起了权游里的夜鬼-_- Buffer Manager Design features 有些vertex buffer的字段 有些物体没有 vertex buffer size一旦allocate，就没办法改变了 Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-10-05 11:56:32 "},"pipeline/cb/resource.html":{"url":"pipeline/cb/resource.html","title":"Checkerboard","keywords":"","body":"Resources Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-03-21 20:29:00 "},"structure/framegraph/resource.html":{"url":"structure/framegraph/resource.html","title":"Frame Graph","keywords":"","body":"Resources Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-03-07 15:49:37 "},"structure/ecs/resource.html":{"url":"structure/ecs/resource.html","title":"ECS","keywords":"","body":"Resources Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-03-07 15:49:37 "},"api/dx/multi_indirect_draw/resource.html":{"url":"api/dx/multi_indirect_draw/resource.html","title":"Multi-Indirect Draw","keywords":"","body":"Resources MaxwellGeng 知乎, DirectX 12 Multi-Indirect Draw Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-03-14 23:13:35 "},"special_effect/atmosphere/resource.html":{"url":"special_effect/atmosphere/resource.html","title":"Atmosphere","keywords":"","body":"Resources 一篇蛮好的blog，很多数学原理说的蛮清楚的，可以作为入门看看 Bruenton 08, Precomputed Atmospheric Scattering 这老哥17年做了一版实现的优化和说明， 我觉得可以大概看下论文的思想，然后细看这个实现的说明，因为这个对于为什么可以那样预计算说的很清楚，可以跟着推导一下就很明白了。 UE4 egsr2020 A Scalable and Production ReadySky and Atmosphere Rendering Technique 腾讯大佬一篇对应的中文分析，把multis-cattering那部分简化的逻辑讲的比较清楚。 Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-07-05 16:24:56 "},"special_effect/atmosphere/ue_ray_marching/ue.html":{"url":"special_effect/atmosphere/ue_ray_marching/ue.html","title":"A Scalable and Production Ready Sky and Atmosphere Rendering Technique","keywords":"","body":"A Scalable and Production Ready Sky and Atmosphere Rendering Technique contributions artifacts leave over transmittance LUT transmittance LUT sky-view LUT aerial-perspective LUT multi-scattering LUT contributions propose a sky and aerial perspective rendering technique re-lying on LUTs to evaluate expensive parts of the lighting integralat lower resolution while maintaining important visual features. propose a novel way to evaluate the contribution of light mul-tiple scattering in the atmosphere. It can approximate an infinitenumber of scattering orders and can also be used to acceleratepath tracing. supportsdynamic time of dayalong with dynamicupdates of the atmospheric properties, all while rendering efficiently on a wide range of devices, from a low-end Apple iPhone6s to consoles and high-end gaming PCs artifacts when using very high scattering coefﬁcients, the hue can be lost or even start to drift as compared to the ground truth. we assume that the light scattering direction is isotropic right after the second bounce. This is in fact an approximation, which is conﬁrmed by a comparison between our model and the reference path tracer. For Mie scattering only, with g = 0.0 and g = 0.8, RMSE is 0.0058 and 0.039, respectively. leave over 之前的LUT的一个问题就是，有volumetric shadowing due to hills and mountains的时候会有些artifacts. epipolar lines [Yus13], shadow volumes [Bru17b], or a variant of shadow volumes extruding meshes from shadow maps [Hoo16] 云和大气包括体积雾都是涉及到volume rendering ozone 的 density 高度分布也是有特定的分布的，这个需要再看下 transmittance LUT transmittance 注意$\\beta$的定义， represent the ratio of light that is lost by interactions with a particle. LUT 任何一点以任一角度到大气边界的transmittance，可以最终转换成以r, $cos(\\theta)$为变量的函数表示 Length ComputeOpticalLengthToTopAtmosphereBoundary( IN(AtmosphereParameters) atmosphere, IN(DensityProfile) profile, Length r, Number mu) { assert(r >= atmosphere.bottom_radius && r = -1.0 && mu = atmosphere.bottom_radius && r = -1.0 && mu 从camera到任意距离的transmittance, 除法关系 DimensionlessSpectrum GetTransmittance( IN(AtmosphereParameters) atmosphere, IN(TransmittanceTexture) transmittance_texture, Length r, Number mu, Length d, bool ray_r_mu_intersects_ground) { assert(r >= atmosphere.bottom_radius && r = -1.0 && mu = 0.0 * m); Length r_d = ClampRadius(atmosphere, sqrt(d * d + 2.0 * r * mu * d + r * r)); Number mu_d = ClampCosine((r * mu + d) / r_d); if (ray_r_mu_intersects_ground) { return min( GetTransmittanceToTopAtmosphereBoundary( atmosphere, transmittance_texture, r_d, -mu_d) / GetTransmittanceToTopAtmosphereBoundary( atmosphere, transmittance_texture, r, -mu), DimensionlessSpectrum(1.0)); } else { return min( GetTransmittanceToTopAtmosphereBoundary( atmosphere, transmittance_texture, r, mu) / GetTransmittanceToTopAtmosphereBoundary( atmosphere, transmittance_texture, r_d, mu_d), DimensionlessSpectrum(1.0)); } } sky-view LUT resolution: 192 * 108 u v 含义 其实是建立了以 天顶方向为z轴， 太阳在垂直于天顶方向的平面的向量为x轴的坐标系。 不管观察位置怎么变，根据viewZenithCosAngle和ZenithHorizonAngle进行归一化，始终在sky-view LUT的上半平面或者下半平面采样。 这样到了外太空需要每帧ray-marching计算。 void SkyViewLutParamsToUv(AtmosphereParameters Atmosphere, in bool IntersectGround, in float viewZenithCosAngle, in float lightViewCosAngle, in float viewHeight, out float2 uv) { float Vhorizon = sqrt(viewHeight * viewHeight - Atmosphere.BottomRadius * Atmosphere.BottomRadius); float CosBeta = Vhorizon / viewHeight; // GroundToHorizonCos float Beta = acos(CosBeta); float ZenithHorizonAngle = PI - Beta; if (!IntersectGround) { float coord = acos(viewZenithCosAngle) / ZenithHorizonAngle; coord = 1.0 - coord; #if NONLINEARSKYVIEWLUT coord = sqrt(coord); // more samples near horizon #endif coord = 1.0 - coord; // dx uv (0, 0) left top uv.y = coord * 0.5f; } else { float coord = (acos(viewZenithCosAngle) - ZenithHorizonAngle) / Beta; #if NONLINEARSKYVIEWLUT coord = sqrt(coord); #endif uv.y = coord * 0.5f + 0.5f; } { float coord = -lightViewCosAngle * 0.5f + 0.5f; // left and right is symmetrical coord = sqrt(coord); uv.x = coord; } // Constrain uvs to valid sub texel range (avoid zenith derivative issue making LUT usage visible) uv = float2(fromUnitToSubUvs(uv.x, 192.0f), fromUnitToSubUvs(uv.y, 108.0f)); } aerial-perspective LUT 3d texture resolution 32 32 32, 32depth = 32 km In-scattering is stored in the RGB channels while the transmittance is stored in the A channel, as the mean of the wavelength dependent RGB transmittance. 绘制LUT的时候，camera的位置为(0, 0, 0), 感觉之后即使位置变了，也是根据这个粗略算的（FASTAERIALPERSPECTIVE_ENABLED）。或者就是每帧都重新算。 multi-scattering LUT 含义 应该希望得到视线方向的积分路径上任意某一点的高阶散射luminance, 在该点会进行最后一次散射(散射后光的传播方向会变成视线方向的反方向)。 2d texture resolution 32 * 32 u v 含义 u是阳光反方向的天顶角cos值，v值是离地球半径高度的归一化值。 assumptions 2阶及2阶以上的multi-scattering在计算时假设是各向同性的，相位函数是一个常量(1 / 4pi) 计算大于2阶的散射时，所有路径上点收到的2阶散射光illuminance是相等的 忽略可见性 float3 GetMultipleScattering(AtmosphereParameters Atmosphere, float3 scattering, float3 extinction, float3 worlPos, float viewZenithCosAngle) { float2 uv = saturate(float2(viewZenithCosAngle*0.5f + 0.5f, (length(worlPos) - Atmosphere.BottomRadius) / (Atmosphere.TopRadius - Atmosphere.BottomRadius))); uv = float2(fromUnitToSubUvs(uv.x, MultiScatteringLUTRes), fromUnitToSubUvs(uv.y, MultiScatteringLUTRes)); float3 multiScatteredLuminance = MultiScatTexture.SampleLevel(samplerLinearClamp, uv, 0).rgb; return multiScatteredLuminance; } 把texture的u和v分成8*8个线程组进行计算。 auto DispatchCS = [&](UINT w, UINT h) { uint32 DispatchSizeX = w;// divRoundUp(w, 8); uint32 DispatchSizeY = h;// divRoundUp(h, 8); uint32 DispatchSizeZ = 1; context->Dispatch(DispatchSizeX, DispatchSizeY, DispatchSizeZ); }; 这里是对某一个高度和太阳天顶角，用compute shader把积分的方向4pi分成了64个采样方向进行求和。 各个方向的2阶散射illuminance存在MultiScatAs1SharedMem. numthreads(1, 1, 64)] void NewMultiScattCS(uint3 ThreadId : SV_DispatchThreadID) { float2 pixPos = float2(ThreadId.xy) + 0.5f; float2 uv = pixPos / MultiScatteringLUTRes; uv = float2(fromSubUvsToUnit(uv.x, MultiScatteringLUTRes), fromSubUvsToUnit(uv.y, MultiScatteringLUTRes)); AtmosphereParameters Atmosphere = GetAtmosphereParameters(); float cosSunZenithAngle = uv.x * 2.0 - 1.0; float3 sunDir = float3(0.0, sqrt(saturate(1.0 - cosSunZenithAngle * cosSunZenithAngle)), cosSunZenithAngle); // We adjust again viewHeight according to PLANET_RADIUS_OFFSET to be in a valid range. float viewHeight = Atmosphere.BottomRadius + saturate(uv.y + PLANET_RADIUS_OFFSET) * (Atmosphere.TopRadius - Atmosphere.BottomRadius - PLANET_RADIUS_OFFSET); float3 WorldPos = float3(0.0f, 0.0f, viewHeight); float3 WorldDir = float3(0.0f, 0.0f, 1.0f); const bool ground = true; const float SampleCountIni = 20;// a minimum set of step is required for accuracy unfortunately const float DepthBufferValue = -1.0; const bool VariableSampleCount = false; const bool MieRayPhase = false; const float SphereSolidAngle = 4.0 * PI; const float IsotropicPhase = 1.0 / SphereSolidAngle; // 八进制来组合theta和phi的index，一位用来做theta的index，一位用来做phi的index // Reference. Since there are many sample, it requires MULTI_SCATTERING_POWER_SERIE to be true for accuracy and to avoid divergences (see declaration for explanations) #define SQRTSAMPLECOUNT 8 const float sqrtSample = float(SQRTSAMPLECOUNT); float i = 0.5f + float(ThreadId.z / SQRTSAMPLECOUNT); // 加上0.5/8的角度偏移 float j = 0.5f + float(ThreadId.z - float((ThreadId.z / SQRTSAMPLECOUNT)*SQRTSAMPLECOUNT)); { float randA = i / sqrtSample; float randB = j / sqrtSample; float theta = 2.0f * PI * randA; float phi = PI * randB; float cosPhi = cos(phi); float sinPhi = sin(phi); float cosTheta = cos(theta); float sinTheta = sin(theta); WorldDir.x = cosTheta * sinPhi; WorldDir.y = sinTheta * sinPhi; WorldDir.z = cosPhi; SingleScatteringResult result = IntegrateScatteredLuminance(pixPos, WorldPos, WorldDir, sunDir, Atmosphere, ground, SampleCountIni, DepthBufferValue, VariableSampleCount, MieRayPhase); MultiScatAs1SharedMem[ThreadId.z] = result.MultiScatAs1 * SphereSolidAngle / (sqrtSample * sqrtSample); LSharedMem[ThreadId.z] = result.L * SphereSolidAngle / (sqrtSample * sqrtSample); } #undef SQRTSAMPLECOUNT // 这里是在把这些值通过二分法累加到第0个元素上 GroupMemoryBarrierWithGroupSync(); // 64 to 32 if (ThreadId.z 0) return; float3 MultiScatAs1 = MultiScatAs1SharedMem[0] * IsotropicPhase; // Equation 7 f_ms float3 InScatteredLuminance = LSharedMem[0] * IsotropicPhase; // Equation 5 L_2ndOrder // MultiScatAs1 represents the amount of luminance scattered as if the integral of scattered luminance over the sphere would be 1. // - 1st order of scattering: one can ray-march a straight path as usual over the sphere. That is InScatteredLuminance. // - 2nd order of scattering: the inscattered luminance is InScatteredLuminance at each of samples of fist order integration. Assuming a uniform phase function that is represented by MultiScatAs1, // - 3nd order of scattering: the inscattered luminance is (InScatteredLuminance * MultiScatAs1 * MultiScatAs1) // - etc. #if MULTI_SCATTERING_POWER_SERIE==0 float3 MultiScatAs1SQR = MultiScatAs1 * MultiScatAs1; float3 L = InScatteredLuminance * (1.0 + MultiScatAs1 + MultiScatAs1SQR + MultiScatAs1 * MultiScatAs1SQR + MultiScatAs1SQR * MultiScatAs1SQR); #else // For a serie, sum_{n=0}^{n=+inf} = 1 + r + r^2 + r^3 + ... + r^n = 1 / (1.0 - r), see https://en.wikipedia.org/wiki/Geometric_series // 这里用了论文里拖到的简化公式来计算的 const float3 r = MultiScatAs1; const float3 SumOfAllMultiScatteringEventsContribution = 1.0f / (1.0 - r); float3 L = InScatteredLuminance * SumOfAllMultiScatteringEventsContribution;// Equation 10 Psi_ms #endif OutputTexture[ThreadId.xy] = float4(MultipleScatteringFactor * L, 1.0f); } Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-03-22 08:27:49 "},"special_effect/atmosphere/multi_scattering/multi_scattering.html":{"url":"special_effect/atmosphere/multi_scattering/multi_scattering.html","title":"multi-scattering计算的一些思考","keywords":"","body":"multi-scattering计算的一些思考 multi-scattering计算的一些思考 从遇到的线上崩溃说起 背景 UE4 新的大气渲染做的multi-scattering简化 优化的方案 从遇到的线上崩溃说起 背景 最近新的赛季上线，有一部分低端配置的玩家报上来说切换了选角界面之后游戏崩溃。万幸的是，有一个同事的笔记本(NVIDIA 750M)可以必现这个问题。后来在复现的过程中发现，切换选角界面再回到游戏中时，大气的效果变了。。于是大概确定是我之前做的大气的锅。我本地调试时发现每次切换选角界面，因为一些配置的缘故，都会切换到我实现的的Bruenton17年的那版算法，可是在我的机器上却并不会崩溃，而且根据玩家的反馈看，只有部分低端机器会有崩溃现象。 于是只能把同事的笔记本“强行征用”，通过增加日志和二分排除pass法等手段，最后发现崩溃就是发生在切换算法时，会重新进行新的预计算(一帧完成)，而预计算如果的multi-scattering迭代超过3阶，GPU计算时间过长，CPU端以为GPU“有问题”了，于是出于保护强行崩溃了。 error: DXGI_ERROR_DEVICE_REMOVED DXGI_ERROR_DEVICE_HUNG 总结得出以下： 以后写了新的功能但并不希望pipeline跑到的时候，配置要十分注意 precompute的multi-scattering很消耗性能，对于低配机来说，如果强行一帧算完，会导致崩溃 于是乎眼下要做的就是优化precompute的性能。忽而想起之前看的UE4的paper有对multi-scattering的简化，于是又翻出来看了看。 UE4 新的大气渲染做的multi-scattering简化 UE4的A Scalable and Production ReadySky and Atmosphere Rendering Technique中基于一定的假设对multi-scattering的计算进行了简化，使得不再需要进行高阶的迭代得到一个比较好的结果。 推导过程如下： ps: 写了个错别字，相位函数。。 优化的方案 总结以上，而且我们游戏目前还是基于地球环境的近地面居多，想到了两种优化方案： 还是用precompute的multi-scattering迭代计算方法，但是分帧计算，这个方法已经在同事的笔记本上试过，可行，但可能有个短暂的预计算时间。 用UE4 paper中的简化计算方法，但做一些改变，即生成一张multi-scattering LUT，在之前precompute的二阶 scattering计算的最后，计算出无穷阶的scattering结果，累加到single scattering上。下周可以实现下这个方案，看下大气的效果如何const float3 r = MultiScatAs1; const float3 SumOfAllMultiScatteringEventsContribution = 1.0f / (1.0 - r); 预计算multi-scattering transfer的时候只计算 MultiScatAs1 Bruenton17 在第二阶multi scattering的第一步 compute the delta_scattering_density_texture的时候 * 1.0f / (1.0 - r) 采样multi-scattering transfer贴图的时候，u是太阳的天顶角cos值，v是相机离地面高度 Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-03-29 07:57:38 "},"special_effect/cloud/resource.html":{"url":"special_effect/cloud/resource.html","title":"Cloud","keywords":"","body":"Resources courses GPU pro 7, Real-Time Volumetric Cloudscapes 15 siggraph course, The Real-time Volumetric Cloudscapes of Horizon: Zero Dawn 17 siggraph course, Nubis: Authoring Real-Time Volumetric Cloudscapes with the Decima Engine 19 siggraph course, Creating the Atmospheric World of Red Dead Redemption 2: A Complete and Integrated Solution ea Frosbite, Physically Based Sky, Atmosphere & Cloud Rendering 2020, Stormscapes: Simulating Cloud Dynamics in the Now implementation Volume Cloud for Unity3D Implementation of Horizon: Zero Dawn's cloud renderer Experiment with generating clouds in real time on low end computer Vulkan-based implementation of clouds from Decima Engine ea_16_cloud Real-time rendering of volumetric clouds FORUM Horizon:zero Dawn Cloud System Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-07-05 15:08:17 "},"simulation/resource.html":{"url":"simulation/resource.html","title":"Simulation","keywords":"","body":"Resources lessons games 103, 基于物理的计算机动画入门 课程主要涵盖四个方向，分别为：1）刚体模拟；2）质点弹簧、约束与布料模拟；3）基于有限元的弹性体模拟；4）流体模拟 games 201, Advanced Physics Engines 基于Taichi物体引擎的关于物理仿真的进阶课程，课程内容包含： Lagrangian/Eulerian/hybrid views; Mass-spring systems; Explicit/implicit time integrators; Smoothed particle hydrodynamics; Implicit FEM solvers; Chorin-Style projection; Krylov-subspace solvers; Multigrid preconditioning; Topology optimization; PIC/FLIP/APIC; Material Point Method; MLS-MPM; Plasticity; High-performance computing; Differentiable physical simulation. Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-05-05 18:14:58 "},"simulation/fluid/resource.html":{"url":"simulation/fluid/resource.html","title":"Fluid","keywords":"","body":"Resources 毛星云，真实感水体渲染技术总结 Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-03-09 16:04:56 "},"course/resource.html":{"url":"course/resource.html","title":"Course","keywords":"","body":"Resources UC Davis 2009, computer graphics 最早我开始学图形学的时候看的课程，课程比较老还是手写黑板教学，虽然都是很初级的知识，但是老师讲的蛮好的，不是照本宣科，说明白里里面的一些道理。 games 101 games 202 UCSD CSE 272: Advanced Image Synthesis UCSD CSE 168 Computer Graphics II: Rendering 台湾大学，Digital Image Synthesis, Fall 2016 一些图形学基础 Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-04-24 13:53:19 "},"course/UC_Davis_Computer_Graphics/UC_Davis_Computer_Graphics.html":{"url":"course/UC_Davis_Computer_Graphics/UC_Davis_Computer_Graphics.html","title":"UC Davis Compute Graphics","keywords":"","body":"UC Davis Computer Graphics UC Davis Computer Graphics Ref Affine Transformation Curves in plane move objects in space Rotations around an arbitrary axis the camera transform Shading and Texturing Visible surface algorithm Ray Tracing Subdivision Surface Shadows part Camera motion Branches of CG Ref 视频 https://www.youtube.com/watch?v=0NbD-c0Ctdk&list=PL_w_qWAQZtAZhtzPI5pkAtcUVgmzdAP8g&index=2 Affine Transformation vector space Curves in plane subdivision curve, Chaikin's Algorithm control point 1/4 3/4 again and again go througn mid-point 反过来 pick some points tan line 3d does not work Bezier Curve attract point B-spline curve continuous->derivative equal bezier vs spline 使用n = 3的贝塞尔曲线原因是要限定相邻的两个分段多项式，在交接点位置的一阶导数相等（斜率相等）和二阶导数相等（斜率的变化率相等） move objects in space a point in space translation scaling center is not in origin, then scaling will cause translation rotate 3d rotate around z axis Rotations around an arbitrary axis model-view-controller easy to debug Rotate around rotate 一个点 一个向量(arbitrary axis）rotate some angles 怎么旋转：把这个点平移到原点，向量旋转到和eg. z axis重合，rotate some angles，再反着做回来 translation 投影 rotate -theta, rotate fi reverse 4d projective point parabola 抛物线 project down as a circle rational splines 有理样条 simulate a camera the camera transform viewing transform pinhole camera camera point direction vector / center of attention up direction angle of view near and far distances 找到一种转换方式把3d的世界转换成视角的2d图像 pyramid -> cube(image space)-> square(screen space) (修正 image space 正负坐标反了) (修正+n， +f) （0, n*tan(a/2), -n）-> (1,1) image space real world Clipping find the real interesting spaces - \"in\" ps. polygon convex, 连接任意两条边的线段都在区域内non-convex -> split into convex pieces glu lookat vs glu perspective glulookat void gluLookAt ( GLdouble eyex, GLdouble eyey, GLdouble eyez, GLdouble centerx, GLdouble centery, GLdouble centerz, GLdouble upx, GLdouble upy, GLdouble upz); 定义了观察者的做坐标，视野中心点在世界坐标系的位置 & 相机的朝向 glu perspective void gluPerspective ( GLdouble fovy, GLdouble aspect, GLdouble zNear, GLdouble zFar); 定义了相机的内在参数，可视角大小， 物体显示在canvas上的x和y方向上的比例，第三个参数zNear,定义距离相机（人眼）最近处物体截面相距的距离。这个值越大，表示观测点距离物体距离越远，看起来物体就比较小，反之则比较大。如果物体运动到距离观测点的距离小于了设定的zNear,则物体不会被绘制在画板上。 第四个参数zFar,定义可观测到的物体的最远处截面相距相机的距离。如果物体运动到距离观测点的距离大于了设定的zFar,则物体不会被绘制的画板上。 do clipping in image space Depth Buffers and Ray Tracing ？something is in front of another image space judge by z coordinates depth buffer 存储最近的物体的深度 如果object的深度大于z buffer的值，不绘制 Ray Tracing painter's algorithm 画家算法首先将场景中的多边形根据深度进行排序，然后按照顺序进行描绘 Color and Shading color lights background light (ambient light) is a constant Lambert's Law reflect base color n is glossness l input, v output h= l+v/2, h 和 n (法线) 夹角越小，反射的光越强 Quaternions rotations structure data on disk? extension of complex 不满足交换律 Unit quaternions rotate around vector v, rotate theta angle ps. 欧拉旋转: Gimbal Lock问题的核心还是在于我们采用了固定的旋转顺序 四元数: chrome-extension://cdonnmffkdaoajfknoeeecmchibpmkmg/assets/pdf/web/viewer.html?file=https%3A%2F%2Fkrasjet.github.io%2Fquaternion%2Fquaternion.pdf Shading and Texturing shading 着色 b means base color -> texturing 10 hyper parameters direct light / spot light -> l change or not n bump mapping ploygons flat shading (平面着色) one color Gouraud Shading -> average color phong shading -> average normal texturing 纹理 texture mapping -> interpolate The hierarchical modeling system how to model things model one thing -> transform to another polygon -> commands not only drawing things -> but also building things Scan Conversion device space split polygon into trapezoids edge track endpoint other staff: light sources Warnock's algorithm Curves and surfaces Chaikin's Algorithm Chaikin's Curve -> control points 1/4 3/4 (fix ratio), initial point may not on the curve 3d surface -> two pairs of control points -> subdivision algorithms Bezier Patch Bezier curve 1/2 initial point is on the curve control points coplanar convex hull property 凸包， curve is not getting away from u variation diminishing 变差缩减性，不会来回摆动 slope at p0 is equal to p0p1, first derivative how about second derivative NURBS non uniform rational Bspline NUBS limit degree of curves Bezier surface four corners on the surface Bezier curves as boundary Visible surface algorithm Painter's algorithm paint all from back to front Binary Tree Sort BSP - trees moving camera position, just move subtree left to right Warnock's algorithm Ray Tracing how it do eye position -> pixel trace to the nearest point first paper reflect shadow refract forward & backward ray tracing backward ray tracing may miss things calculate the nearest point Subdivision Surface Chaikin's Curve Chaikin's Surface/Doo-Sabin Surface 不同方向上做1/4 3/4（Chaikin's points），连接，划分成一个个小的mesh how to save such data ? -> split edge a pointer -> start point a pointer -> next edge a pointer -> neighbor subEdge Catmull-Clark Subdivision loop subdivision (triangle meshes) vertex point (half way half way)& edge point (mid point) Face point: F = average of all points defining the face Edge point: E = average of tow adjoining face points and the two vertices Vertex point: V = (average of all face points + average of all edge poins + constant origin vectors )/ 4 how to model sphere -> triangle data structure: 3 vertexes + 3 pointers to neighbors Shadows part ground plane (need a point and a normal) avoid sharp shadows -> texture with fuzzy edge polygons too complex -> general bounding box shadow volumes count numbers of into a shadow volumes (+1) and out of a shadow volumes (-1) sum = zero : no shadows ps. umbra penumbra depth buffer shadows for each light source, create a \"picture\" (image space, z buffer) for each eye point, create a \"picture\" (z buffer) reconcile these pictures Camera motion simulate camera motion path as smooth curve Lagrange interpolation spline Ferguson curve Catmull 二次导等于间隔点连线 c1 连续 curve ps Branches of CG Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-02-28 11:12:04 "},"course/UCSD_CSE_272_part1/part1.html":{"url":"course/UCSD_CSE_272_part1/part1.html","title":"Intro & Simple BSDF","keywords":"","body":"UCSD CSE 272 : Advanced Image Synthesis --- intro & simple BSDF part UCSD CSE 272 : Advanced Image Synthesis --- intro & simple BSDF part intro course overview smallpt : path tracing in 30 minutes What is the color of a pixel? what‘s more lajolla geometry primitive next event estimation multi importance sampling textures shading normals embree BSDF how to obtain BSDF build a model for BSDF Microfacet theory Uber BSDF Uber BSDF Disney BSDF Autodesk Standard Surface Unreal Engine 4 Physically-based Material Normal/Displacement Map Filtering mipmap normal map --- using NDF principle solutions LEAN LEADR Yan Ling-Qi --- 还原复杂normal下的高光 procedurally generate normals more researches intro course overview smallpt : path tracing in 30 minutes What is the color of a pixel? reconstruction path tracing intersection trace diffuse relfection mirror reflection refraction lighting termination what‘s more lajolla geometry primitive struct Sphere : public ShapeBase { Vector3 position; Real radius; }; struct TriangleMesh : public ShapeBase { /// TODO: make these portable to GPUs std::vector positions; std::vector indices; std::vector normals; std::vector uvs; /// Below are used only when the mesh is associated with an area light Real total_area; /// For sampling a triangle based on its area TableDist1D triangle_sampler; }; // To add more shapes, first create a struct for the shape, add it to the variant below, // then implement all the relevant functions below. using Shape = std::variant; next event estimation in addition to cosine-weighted hemisphere sampling, also sample a point on light light sampling struct pdf_point_on_shape_op { Real operator()(const Sphere &sphere) const; Real operator()(const TriangleMesh &mesh) const; const PointAndNormal &point_on_shape; const Vector3 &ref_point; }; multi importance sampling textures 用一阶Taylor展开来根本的解释mip map level原理 path tracing 怎么计算偏导数 ```cpp /// We adopt an approach for ray differentials /// that is used in Renderman. /// See Section 6.6 in \"RenderMan: /// An Advanced Path Tracing Architecture for Movie Rendering\" /// https://graphics.pixar.com/library/RendermanTog2018/paper.pdf /// The idea is to simplify Igehy's ray differential by only /// storing two quantities: a \"radius\" that describes positional /// differential, and a \"spread\" that describes directional differential. /// For glossy/diffuse surfaces, Renderman used a heuristics based on the /// PDF of the sampling direction and use larger spread for low PDF. /// Here we use an even simpler heuristics: we linearly blend /// between the specular spread and a constant based on roughness. struct RayDifferential { // Radius is approximately (length(dp/dx) + length(dp/dy)) / 2 // Spread is approximately (length(dd/dx) + length(dd/dy)) / 2 // p is ray position, d is ray direction. Real radius = 0, spread = 0; // The units are pixels. }; ``` shading normals chrome-extension://cdonnmffkdaoajfknoeeecmchibpmkmg/assets/pdf/web/viewer.html?file=https%3A%2F%2Fjo.dreggn.org%2Fhome%2F2021_terminator.pdf embree BSDF how to obtain BSDF build a model for BSDF Microfacet theory normal distribution function microsurface geometry profile Fresnel --- ratio of reflection complex for metals multiple scattering Uber BSDF This “Uber” BSDF includes multiple layers to create a wide variety of materials. Uber BSDF Disney BSDF diffuse metal & clear coat glass sheen Autodesk Standard Surface clear coat metal sheen Unreal Engine 4 Physically-based Material Normal/Displacement Map Filtering mipmap normal map --- using NDF principle 核心思想是通过局部的normal map 来推导出NDF分布 solutions LEAN 拟合 Beckmann NDF 这个难道不就是specular AA ？？ 拟合 geometry term result LEADR displacement and reflectance mapping Yan Ling-Qi --- 还原复杂normal下的高光 核心思想是 count texels on the normal map given and ω ω′ 实际是用Guassian distribution来拟合normal朝向的权重 procedurally generate normals more researches Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-04-06 14:23:50 "},"course/UCSD_CSE_272_part2/part2.html":{"url":"course/UCSD_CSE_272_part2/part2.html","title":"Advanced BSDF","keywords":"","body":"UCSD CSE 272 : Advanced Image Synthesis --- advanced BSDF Layered BSDF a comprehensive framework for rendering layered materials basic principle special case : pile of glass plates [Stokes 1860] general case : adding equation [Grant and Hunt 1969] general layered BSDF construction [Jakob 2014] Efficient Rendering of Layered Materials using an Atomic Decomposition with Statistical Operators basic principle Belcour’s algorithm Position-Free Monte Carlo Simulation for Arbitrary Layered BSDFs basic principle recent research Hair and Cloth physical structures hair rendering categories strand-based models [Marschner et al. 2003] modeling the geometry of hair strands ray-curve intersection hair BSDF cloth rendering categories Wave-based BSDFs what is light why do we see things Huygen’s principle real-life wave optics effects Wave BSDF in computer graphics thin-film BSDF adding diffraction in microfacet models Other wave optics work Layered BSDF how to modeling layered BSDF a comprehensive framework for rendering layered materials http://www.cs.cornell.edu/projects/layered-sg14/ basic principle adding equation: 把每一层的光照作用累积起来 special case : pile of glass plates [Stokes 1860] general case : adding equation [Grant and Hunt 1969] general layered BSDF construction [Jakob 2014] use a Fourier basis to compress the matrices https://www.pbr-book.org/3ed-2018/Reflection_Models/Fourier_Basis_BSDFs downside need to store a huge sparse matrix (in Fourier domain) texturing is hard Efficient Rendering of Layered Materials using an Atomic Decomposition with Statistical Operators basic principle use sum of GGX lobes to represent multiple scattering between layers approximate the R&T matrices using Gaussians for a given direction ω Belcour’s algorithm each layer energy mean variance add all of layers Position-Free Monte Carlo Simulation for Arbitrary Layered BSDFs basic principle just compute the multiple scattering using Monte Carlo integration 降维 the horizontal distance doesn’t matter in a BSDF solve a small “1D” rendering equation inside the material recent research Hair and Cloth physical structures made of fibers hair rendering categories strand-based models [Marschner et al. 2003] modeling the geometry of hair strands option1 --- polylines(多线段) but lines don’t have thickness! option 2 --- connected cylinders(圆柱) rendering cylinders is a bit expensive option 3 --- connected quads(有点类似于billboard的四边形) quads always face towards the viewers use shading normal to fake cylinder appearances option 4 --- connected Bezier curves smoother appearance and less storage cost can use either the planar approximation or have actual cylindrical shape can use shading normal to represent orientation variation within the curve ray-curve intersection hair BSDF or “BCSDF” (Bidirectional Curve Scattering Distribution Function) or “BFSDF” (F=Fiber) lighting model use a lobe for each scattering mode Common assumption: separable lobes for longitudinal & azimuthal longitudinal scattering Marschner et al. [2003]: fit different wrapped Gaussians around the half-angle d’Eon et al. [2011]’s proposal: use a von-Mises-like distribution http://www.eugenedeon.com/wp-content/uploads/2014/04/egsr azimuthal scattering Common assumption: the circular section is isotropic (i.e. it’s not an ellipse) Chiang et al. [2016] proposed to use a logistic distribution volumetric absorption and Fresnel 3 lobes for R, TRT, TT; 1 lobe to compensate energy Bells and whistles(really interesting) 动物毛发和人类毛发的差别: volumetric scattering 不同人种真实的头发截面形状: elliptical cross section 不区分longitudinal和azimuthal: non-separable lobes real-time rendering cloth rendering categories 如果感兴趣，再找对应的paper深入了解下 Wave-based BSDFs what is light why do we see things Huygen’s principle 用复数来表示波 real-life wave optics effects compact disks caused by many small “slits” soap bubbles caused by “thin-film interference” dispersion(色散) hologram(全息图) Wave BSDF in computer graphics thin-film BSDF idea replace the Fresnel term in Cook-Sparrow-Torrance adding diffraction in microfacet models Other wave optics work Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2022-04-24 13:47:03 "},"engine/filament/resource.html":{"url":"engine/filament/resource.html","title":"Filament","keywords":"","body":"Resources PBR Physically Based Rendering in Filament, 官方文档 对应的中文翻译 Filament Materials Guide, 官方材质文档 Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-01 20:30:41 "},"engine/ue/resource.html":{"url":"engine/ue/resource.html","title":"Unreal","keywords":"","body":"Resources PBR Real Shading inUnreal Engine 4 Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-01 20:30:20 "},"volume/pbr_volume_scattering/pbr_volume_scattering.html":{"url":"volume/pbr_volume_scattering/pbr_volume_scattering.html","title":"Volume Scattering","keywords":"","body":"PBR Chapter11 Volume Scattering Introduction Volume Scattering Processes Phase Function Media BSSRDF Introduction we have assumed that scenes are made up of collections of surfaces in a vacuum, which means that radiance is constant along rays between surfaces introduces the mathematics to describe how light is affected as it passes through participating media—large numbers of very small particles distributed throughout a region of 3D space volume scattering models are based on the assumption that there are so many particles that scattering is best modeled as a probabilistic process, rather than directly accounting for individual interactions with particles tracking paths with hundreds or thousands of scattering interactions quickly becomes impractical, it is preferable to aggregate the overall effect of the underlying scattering process in a function that relates scattering between points where light enters and leaves the medium contents basic physical processes medium BSSRDF Volume Scattering Processes Absorption: the reduction in radiance due to the conversion of light to another form of energy, such as heat Emission: radiance that is added to the environment from luminous particles Scattering: radiance heading in one direction that is scattered to other directions due to collisions with particles Out-Scattering and Attenuation albedo mean free path theta 单位是 1/m transmittance Beer's Law In scattering Phase Function parameterized models (which can be used to fit a function with a small number of parameters to measured data) analytic models that are based on deriving the scattered radiance distribution that results from particles with known shape and material Henyey–Greenstein phase function meaning of g a weighted sum of phase functions data structure Media A key operation that Medium implementations must perform is to compute the beam transmittance the boundary between two different types of scattering media is always represented by the surface of a GeometricPrimitive sometimes we only need the shape for the boundary surface it provides to delimit a participating medium boundary and we don’t want to see the surface itself Material * that is nullptr , indicating that they do not affect light passing through them bsdf is null (not affect light transport) or not null GridDensityMedium BSSRDF there is thus an implicit assumption that the index of refraction is constant throughout the medium separable BSSRDFs For high-albedo media, the scattered radiance distribution is generally fairly isotropic and the Fresnel transmittance is the most important factor for defining the final directional distribution Directional variation can be meaningful for low-albedo media; in that case, this approximation is less accurate Lo diffusion profile Second approximation, which assumes that the surface is not only locally planar but that it is the distance between the points rather than their actual locations that affects the value of the BSSRDF tabulated BSSRDF S_r extinction coefficient = 1 fix the index of refraction and scattering anisotropy parameter Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2023-06-12 11:45:24 "},"volume/pbr_volume_rendering/pbr_volume_rendering.html":{"url":"volume/pbr_volume_rendering/pbr_volume_rendering.html","title":"Light-Transport II: Volume Rendering","keywords":"","body":"PBR Chapter15 Light Transport II: Volume Rendering The Equation of Transfer(LTE) Generalized Path Space Sampling Volume Scattering Volumetric Light Transport Sampling Subsurface Reflection Functions Subsurface Scattering Using the Diffusion Profile The Equation of Transfer(LTE) Two effects that contribute to radiance along the ray The emitted and reflected radiance from the surface. This radiance may be attenuated by the participating media; the beam transmittance from the ray origin to the point accounts for this. the added radiance along the ray due to volume scattering and emission but only up to the point where the ray intersects the surface Generalized Path Space path integration An integral that can consider an arbitrary sequence of both 2D surface locations A and 3D positions in a participating medium V . a sum of many integrals considering all possible sequences of surface and volume scattering events f (BSDF or phase function) G Sampling Volume Scattering Without loss of generality, the following discussion assumes that there is always a surface at some distance. two cases when path tracing particle intersection medium interaction probability Homogeneous Medium attenuation coefficients varied by wavelength a uniform sample is first used to select a spectral channel i sample distance with transmittance pdf interaction lighting calculation weighting factor Heterogeneous Medium regular tracking becomes costly when there are many voxels ray marching introduces systemic statistical bias which generally won’t converge to the right result delta tracking （unbiased) filling the medium with additional (virtual) particles until its attenuation coefficient is constant everywhere however whenever an interaction with a particle occurs, it is still necessary to determine if it involved a “real” or a “virtual” particle the scattering and absorption coefficients are still permitted to vary with respect to wavelength — however, their sum must be uniform steps precompute the inverse of the maximum density scale factor over the entire medium delta tracking 会把media的 density “填充” 成 maximum density transforming the ray into the medium coordinate system and normalizing the ray direction computes the parametric range of the ray’s overlap with the medium’s bounds each delta-tracking iteration performs a standard exponential step through the uniform medium 实际是根据当前位置的density / maximum density 来判断是否是real particles compute the transmittance along a ray segment Sampling Phase Function The PDF for the Henyey–Greenstein phase function is separable into theta and phi components p(phi) = 1 / (2 * pi) pdf of theta Volumetric Light Transport VolPathIntegrator’s main responsibility is to implement the Li() method. Usually, the ray is first intersected with the surfaces in the scene to find the closest surface intersection, if any. Next, participating media are accounted. In scenes with very dense scattering media, a more efficient implementation would be to first sample a medium interaction. Sampling Subsurface Reflection Functions sample points p_i on the surface and to compute the incident radiance at these points an efficient way to compute the specific value of the BSSRDF S for each sampled point p_i and incident direction VolPathIntegrator path tracer integration to evaluate the BSSRDF BSSRDF sampling sampling the SeparableBSSRDF assume that the BSSRDF is only sampled for rays that are transmitted through the surface boundary, so 1 - F_r(cos theta_o) has nothing needs to sample S_w(w_i) defined as a diffuse-like term scaled by the normalized Fresnel transmission just uses the default cosine-weighted sampling routine to calculate pdf S_p sampling an out position need a way of mapping a 2D distribution function onto an arbitrary surface using a parameterization of the surface in the neighborhood of the outgoing position a simpler approach difficulties first two problems can be addressed with introducing additional tailored sampling distributions and combining them using multiple importance sampling per wavelength additionally replicated three times with different projection axes given by the basis vectors of a local frame stages choosing a projection axis calc all based on local coordinated of p_o allocate a fairly large portion (50%) of the sample budget to perpendicular rays. The other half is equally shared between tangential projections uniformly choose a spectral channel and re-scale u1 once more sampling S_r in order to reduce the computational expense of the ray-tracing step, the probe ray is clamped to a sphere of radius r_max around p_o calc probe trace start calc intersection chain and choose one from it uniformly calc the pdf and the S_p sampling the TabulatedBSSRDF Subsurface Scattering in Path Tracer Subsurface Scattering Using the Diffusion Profile initialize the TabulatedBSSRDF with a radial profile function S_r that accurately describes subsurface scattering for given properties of the scattering medium (theta_a, theta_s, the phase function asymmetry parameter g, and the relative index of refraction). photon beam diffusion (PBD) assumption the distribution of light in the translucent medium is modeled with the diffusion approximation homogeneous scattering properties throughout the \"semi-infinite\" medium builds upon the separable BSSRDF approximation of Equation precompute S_r for a range of radii and albedo values and use the results to populate the BSSRDFTable of a TabulatedBSSRDF principle of similarity for an anisotropically scattering medium with a high albedo, the medium can instead be modeled as having an isotropic phase function with appropriately modified scattering and attenuation coefficients isotropization due to multiple scattering events from the Henyey–Greenstein phase function. As n grows large, this converges to the isotropic phase function 1/ (4 * pi). reduced scattering coefficient reduced albedo 因为假设了isotropic phase function，所以需要改变scattering coefficients来弥补假设带来的artifacts， theta_s probability of scattering diffusion theory Copyright © tingxia.top 2021 all right reserved，powered by Gitbook该文件修订时间： 2023-06-12 11:45:12 "}}